<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">

<!--Converted with LaTeX2HTML 2002-2-1 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Solving linear equation systems</TITLE>
<META NAME="description" CONTENT="Solving linear equation systems">
<META NAME="keywords" CONTENT="technical">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META NAME="Generator" CONTENT="LaTeX2HTML v2002-2-1">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="technical.css">

<LINK REL="next" HREF="node100.html">
<LINK REL="previous" HREF="node98.html">
<LINK REL="up" HREF="node97.html">
<LINK REL="next" HREF="node100.html">
</HEAD>

<BODY LANG="EN" BGCOLOR="#FFFFFF" TEXT="#000000" LINK="#0000FF" VLINK="#800080" ALINK="#FF0000">

<DIV CLASS="navigation"><B> Next:</B> <A NAME="tex2html2206"
  HREF="node100.html">Polynomial approximations</A>
<B>Up:</B> <A NAME="tex2html2202"
  HREF="node97.html">Mathematical background</A>
<B> Previous:</B> <A NAME="tex2html2196"
  HREF="node98.html">N-port matrix conversions</A>
<BR> <P>
</DIV>
<!--End of Navigation Panel-->
<!--Table of Child-Links-->
<A NAME="CHILD_LINKS"><STRONG>Subsections</STRONG></A>

<UL CLASS="ChildLinks">
<LI><A NAME="tex2html2207"
  HREF="node99.html#SECTION001621000000000000000">Matrix inversion</A>
<LI><A NAME="tex2html2208"
  HREF="node99.html#SECTION001622000000000000000">Gaussian elimination</A>
<UL>
<LI><A NAME="tex2html2209"
  HREF="node99.html#SECTION001622100000000000000">Step 1: Forward elimination</A>
<LI><A NAME="tex2html2210"
  HREF="node99.html#SECTION001622200000000000000">Finding an appropriate pivot element</A>
<LI><A NAME="tex2html2211"
  HREF="node99.html#SECTION001622300000000000000">Step 2: Backward substitution</A>
</UL>
<BR>
<LI><A NAME="tex2html2212"
  HREF="node99.html#SECTION001623000000000000000">Gauss-Jordan method</A>
<LI><A NAME="tex2html2213"
  HREF="node99.html#SECTION001624000000000000000">LU decomposition</A>
<UL>
<LI><A NAME="tex2html2214"
  HREF="node99.html#SECTION001624100000000000000">Step 1: LU decomposition</A>
<LI><A NAME="tex2html2215"
  HREF="node99.html#SECTION001624200000000000000">Step 2: Forward substitution</A>
<LI><A NAME="tex2html2216"
  HREF="node99.html#SECTION001624300000000000000">Step 3: Backward substitution</A>
</UL>
<BR>
<LI><A NAME="tex2html2217"
  HREF="node99.html#SECTION001625000000000000000">QR decomposition</A>
<UL>
<LI><A NAME="tex2html2218"
  HREF="node99.html#SECTION001625100000000000000">Step 1: QR decomposition</A>
<LI><A NAME="tex2html2219"
  HREF="node99.html#SECTION001625200000000000000">Step 2: Forming the new right hand side</A>
<LI><A NAME="tex2html2220"
  HREF="node99.html#SECTION001625300000000000000">Step 3: Backward substitution</A>
<LI><A NAME="tex2html2221"
  HREF="node99.html#SECTION001625400000000000000">Motivation</A>
<LI><A NAME="tex2html2222"
  HREF="node99.html#SECTION001625500000000000000">QR decomposition with column pivoting</A>
<LI><A NAME="tex2html2223"
  HREF="node99.html#SECTION001625600000000000000">Least norm problem</A>
</UL>
<BR>
<LI><A NAME="tex2html2224"
  HREF="node99.html#SECTION001626000000000000000">Singular value decomposition</A>
<UL>
<LI><A NAME="tex2html2225"
  HREF="node99.html#SECTION001626100000000000000">Notation</A>
<LI><A NAME="tex2html2226"
  HREF="node99.html#SECTION001626200000000000000">Householder reflector</A>
<UL>
<LI><A NAME="tex2html2227"
  HREF="node99.html#SECTION001626210000000000000">Specific case</A>
<LI><A NAME="tex2html2228"
  HREF="node99.html#SECTION001626220000000000000">General case</A>
</UL>
<LI><A NAME="tex2html2229"
  HREF="node99.html#SECTION001626300000000000000">Givens rotation</A>
<LI><A NAME="tex2html2230"
  HREF="node99.html#SECTION001626400000000000000">Eigenvalues of a 2-by-2 matrix</A>
<LI><A NAME="tex2html2231"
  HREF="node99.html#SECTION001626500000000000000">Step 1: Bidiagonalization</A>
<LI><A NAME="tex2html2232"
  HREF="node99.html#SECTION001626600000000000000">Step 2: Matrix reconstructions</A>
<LI><A NAME="tex2html2233"
  HREF="node99.html#SECTION001626700000000000000">Step 3: Diagonalization - shifted QR iteration</A>
<UL>
<LI><A NAME="tex2html2234"
  HREF="node99.html#SECTION001626710000000000000">Single shifted QR step.</A>
<LI><A NAME="tex2html2235"
  HREF="node99.html#SECTION001626720000000000000">Computation of the Wilkinson shift.</A>
<LI><A NAME="tex2html2236"
  HREF="node99.html#SECTION001626730000000000000">Zeros on the diagonal or super-diagonal.</A>
</UL>
<LI><A NAME="tex2html2237"
  HREF="node99.html#SECTION001626800000000000000">Step 4: Solving the equation system</A>
</UL>
<BR>
<LI><A NAME="tex2html2238"
  HREF="node99.html#SECTION001627000000000000000">Jacobi method</A>
<LI><A NAME="tex2html2239"
  HREF="node99.html#SECTION001628000000000000000">Gauss-Seidel method</A>
<LI><A NAME="tex2html2240"
  HREF="node99.html#SECTION001629000000000000000">A comparison</A>
</UL>
<!--End of Table of Child-Links-->
<HR>

<H1><A NAME="SECTION001620000000000000000"></A>
<A NAME="sec:linEQS"></A>
<BR>
Solving linear equation systems
</H1>

<P>
When dealing with non-linear networks the number of equation systems
to be solved depends on the required precision of the solution and the
average necessary iterations until the solution is stable.  This
emphasizes the meaning of the solving procedures choice for different
problems.

<P>
<P>
The equation systems
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\left[A\right] \cdot \left[x\right] = \left[z\right]
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="95" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img267.png"
 ALT="$\displaystyle \left[A\right] \cdot \left[x\right] = \left[z\right]$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">58</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
solution can be written as
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\left[x\right] = \left[A\right]^{-1} \cdot \left[z\right]
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="113" HEIGHT="40" ALIGN="MIDDLE" BORDER="0"
 SRC="img269.png"
 ALT="$\displaystyle \left[x\right] = \left[A\right]^{-1} \cdot \left[z\right]$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">59</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>

<H2><A NAME="SECTION001621000000000000000">
Matrix inversion</A>
</H2>

<P>
The elements <!-- MATH
 $\beta_{\mu\nu}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2776.png"
 ALT="$ \beta_{\mu\nu}$"></SPAN> of the inverse of the matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img380.png"
 ALT="$ A$"></SPAN> are
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\beta_{\mu\nu} = \frac{A_{\mu\nu}}{det A}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="87" HEIGHT="53" ALIGN="MIDDLE" BORDER="0"
 SRC="img2777.png"
 ALT="$\displaystyle \beta_{\mu\nu} = \frac{A_{\mu\nu}}{det A}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">60</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
whereas <!-- MATH
 $A_{\mu\nu}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="31" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2778.png"
 ALT="$ A_{\mu\nu}$"></SPAN> is the matrix elements <!-- MATH
 $a_{\mu\nu}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2779.png"
 ALT="$ a_{\mu\nu}$"></SPAN> cofactor.
The cofactor is the sub determinant (i.e. the minor) of the element
<!-- MATH
 $a_{\mu\nu}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2779.png"
 ALT="$ a_{\mu\nu}$"></SPAN> multiplied with <!-- MATH
 $(-1)^{\mu + \nu}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="62" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img2780.png"
 ALT="$ (-1)^{\mu + \nu}$"></SPAN>.  The determinant of a
square matrix can be recursively computed by either of the following
equations.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><TABLE CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="162" HEIGHT="62" ALIGN="MIDDLE" BORDER="0"
 SRC="img2781.png"
 ALT="$\displaystyle det A = \sum_{\mu = 1}^{n} a_{\mu\nu}\cdot A_{\mu\nu} \quad$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH">using the <SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img2782.png"
 ALT="$ \nu$"></SPAN>-th column</SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">61</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="161" HEIGHT="62" ALIGN="MIDDLE" BORDER="0"
 SRC="img2783.png"
 ALT="$\displaystyle det A = \sum_{\nu = 1}^{n} a_{\mu\nu}\cdot A_{\mu\nu} \quad$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH">using the <SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img122.png"
 ALT="$ \mu$"></SPAN>-th row</SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">62</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
This method is called the Laplace expansion.  In order to save
computing time the row or column with the most zeros in it is used for
the expansion expressed in the above equations.  A sub determinant
<SPAN CLASS="MATH"><IMG
 WIDTH="53" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img2784.png"
 ALT="$ (n-1)$"></SPAN>-th order of a matrix's element <!-- MATH
 $a_{\mu\nu}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2779.png"
 ALT="$ a_{\mu\nu}$"></SPAN> of <SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img383.png"
 ALT="$ n$"></SPAN>-th order is
the determinant which is computed by cancelling the <SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img122.png"
 ALT="$ \mu$"></SPAN>-th row and
<SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img2782.png"
 ALT="$ \nu$"></SPAN>-th column.  The following example demonstrates calculating the
determinant of a 4th order matrix with the elements of the 3rd row.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><TABLE CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="149" HEIGHT="94" ALIGN="MIDDLE" BORDER="0"
 SRC="img2785.png"
 ALT="$\displaystyle \begin{vmatrix}a_{11} &amp; a_{12} &amp; a_{13} &amp; a_{14}\\ a_{21} &amp; a_{22...
... &amp; a_{32} &amp; a_{33} &amp; a_{34}\\ a_{41} &amp; a_{42} &amp; a_{43} &amp; a_{44}\\ \end{vmatrix}$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="305" HEIGHT="75" ALIGN="MIDDLE" BORDER="0"
 SRC="img2786.png"
 ALT="$\displaystyle = a_{31} \begin{vmatrix}a_{12} &amp; a_{13} &amp; a_{14}\\ a_{22} &amp; a_{23...
... &amp; a_{14}\\ a_{21} &amp; a_{23} &amp; a_{24}\\ a_{41} &amp; a_{43} &amp; a_{44}\\ \end{vmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">63</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD>&nbsp;</TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="301" HEIGHT="75" ALIGN="MIDDLE" BORDER="0"
 SRC="img2787.png"
 ALT="$\displaystyle + a_{33} \begin{vmatrix}a_{11} &amp; a_{12} &amp; a_{14}\\ a_{21} &amp; a_{22...
... &amp; a_{13}\\ a_{21} &amp; a_{22} &amp; a_{23}\\ a_{41} &amp; a_{42} &amp; a_{43}\\ \end{vmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
&nbsp;&nbsp;&nbsp;</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
This recursive process for computing the inverse of a matrix is most
easiest to be implemented but as well the slowest algorithm.  It
requires approximately <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2788.png"
 ALT="$ n!$"></SPAN> operations.

<P>

<H2><A NAME="SECTION001622000000000000000">
Gaussian elimination</A>
</H2>

<P>
The Gaussian algorithm for solving a linear equation system is done in
two parts: forward elimination and backward substitution.  During
forward elimination the matrix A is transformed into an upper
triangular equivalent matrix.  Elementary transformations due to an
equation system having the same solutions for the unknowns as the
original system.

<P>
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
A =
\begin{bmatrix}
a_{11} & a_{12} & \ldots & a_{1n}\\
a_{21} & a_{22} & \ldots & a_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
a_{n1} & a_{n2} & \ldots & a_{nn}
\end{bmatrix}
\rightarrow
\begin{bmatrix}
a_{11} & a_{12} & \ldots & a_{1n}\\
0 & a_{22} & \ldots & a_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
0 & \ldots & 0 & a_{nn}
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="377" HEIGHT="103" ALIGN="MIDDLE" BORDER="0"
 SRC="img2789.png"
 ALT="$\displaystyle A = \begin{bmatrix}a_{11} &amp; a_{12} &amp; \ldots &amp; a_{1n}\\ a_{21} &amp; a...
...2n}\\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\ 0 &amp; \ldots &amp; 0 &amp; a_{nn} \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">64</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The modifications applied to the matrix A in order to achieve this
transformations are limited to the following set of operations.

<UL>
<LI>multiplication of a row with a scalar factor
</LI>
<LI>addition or subtraction of multiples of rows
</LI>
<LI>exchanging two rows of a matrix
</LI>
</UL>

<P>

<H3><A NAME="SECTION001622100000000000000">
Step 1: Forward elimination</A>
</H3>

<P>
The transformation of the matrix A is done in <!-- MATH
 $\mathrm{n - 1}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="40" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2790.png"
 ALT="$ \mathrm{n - 1}$"></SPAN>
elimination steps.  The new matrix elements of the k-th step with
<!-- MATH
 $\mathrm{k = 1, \ldots, n - 1}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="113" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2791.png"
 ALT="$ \mathrm{k = 1, \ldots, n - 1}$"></SPAN> are computed with the following
recursive formulas.

<P>
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><TABLE CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="23" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2792.png"
 ALT="$\displaystyle a_{ij}$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img755.png"
 ALT="$\displaystyle = 0$"></SPAN></TD>
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="111" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2793.png"
 ALT="$\displaystyle i = k+1, \ldots, n$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH">and&nbsp;<IMG
 WIDTH="41" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2794.png"
 ALT="$\displaystyle j = k$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">65</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="23" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2792.png"
 ALT="$\displaystyle a_{ij}$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="143" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img2795.png"
 ALT="$\displaystyle = a_{ij} - a_{kj} \cdot a_{ik} / a_{kk}$"></SPAN></TD>
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="111" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2793.png"
 ALT="$\displaystyle i = k+1, \ldots, n$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH">and&nbsp;<IMG
 WIDTH="113" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2796.png"
 ALT="$\displaystyle j = k+1, \ldots, n$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">66</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2797.png"
 ALT="$\displaystyle z_{i}$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="129" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img2798.png"
 ALT="$\displaystyle = z_{i} - z_{k} \cdot a_{ik} / a_{kk}$"></SPAN></TD>
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="111" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2793.png"
 ALT="$\displaystyle i = k+1, \ldots, n$"></SPAN></TD>
<TD>&nbsp;</TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">67</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The triangulated matrix can be used to calculate the determinant very
easily.  The determinant of a triangulated matrix is the product of
the diagonal elements.  If the determinant <SPAN CLASS="MATH"><IMG
 WIDTH="37" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2799.png"
 ALT="$ det A$"></SPAN> is non-zero the
equation system has a solution.  Otherwise the matrix A is singular.

<P>
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
det A = a_{11}\cdot a_{22}\cdot \ldots \cdot a_{nn} = \prod_{i=1}^{n} a_{ii}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="243" HEIGHT="62" ALIGN="MIDDLE" BORDER="0"
 SRC="img2800.png"
 ALT="$\displaystyle det A = a_{11}\cdot a_{22}\cdot \ldots \cdot a_{nn} = \prod_{i=1}^{n} a_{ii}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">68</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
When using row and/or column pivoting the resulting determinant may
differ in its sign and must be multiplied with <SPAN CLASS="MATH"><IMG
 WIDTH="48" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img2801.png"
 ALT="$ (-1)^m$"></SPAN> whereas <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img56.png"
 ALT="$ m$"></SPAN> is
the number of row and column substitutions.

<P>

<H3><A NAME="SECTION001622200000000000000">
Finding an appropriate pivot element</A>
</H3>

<P>
The Gaussian elimination fails if the pivot element <SPAN CLASS="MATH"><IMG
 WIDTH="27" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2802.png"
 ALT="$ a_{kk}$"></SPAN> turns to
be zero (division by zero).  That is why row and/or column pivoting
must be used before each elimination step.  If a diagonal element
<!-- MATH
 $a_{kk} = 0$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="56" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2803.png"
 ALT="$ a_{kk} = 0$"></SPAN>, then exchange the pivot row <SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$ k$"></SPAN> with the row <SPAN CLASS="MATH"><IMG
 WIDTH="48" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2804.png"
 ALT="$ m &gt; k$"></SPAN>
having the coefficient with the largest absolute value.  The new pivot
row is <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img56.png"
 ALT="$ m$"></SPAN> and the new pivot element is going to be <SPAN CLASS="MATH"><IMG
 WIDTH="31" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2805.png"
 ALT="$ a_{mk}$"></SPAN>.  If no
such pivot row can be found the matrix is singular.

<P>
<P>
Total pivoting looks for the element with the largest absolute value
within the matrix and exchanges rows and columns.  When exchanging
columns in equation systems the unknowns get reordered as well.  For
the numerical solution of equation systems with Gaussian elimination
column pivoting is clever, and total pivoting recommended.

<P>
<P>
In order to improve numerical stability pivoting should also be
applied if <!-- MATH
 $a_{kk} \ne 0$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="56" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2806.png"
 ALT="$ a_{kk} \ne 0$"></SPAN> because division by small diagonal elements
propagates numerical (rounding) errors.  This appears especially with
poorly conditioned (the two dimensional case: two lines with nearly
the same slope) equation systems.

<P>

<H3><A NAME="SECTION001622300000000000000">
Step 2: Backward substitution</A>
</H3>

<P>
The solutions in the vector x are obtained by backward substituting
into the triangulated matrix.  The elements of the solution vector x
are computed by the following recursive equations.

<P>
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><TABLE CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="21" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2807.png"
 ALT="$\displaystyle x_{n}$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="49" HEIGHT="43" ALIGN="MIDDLE" BORDER="0"
 SRC="img2808.png"
 ALT="$\displaystyle = \frac{z_{n}}{a_{nn}}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">69</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img409.png"
 ALT="$\displaystyle x_{i}$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="153" HEIGHT="62" ALIGN="MIDDLE" BORDER="0"
 SRC="img2809.png"
 ALT="$\displaystyle = \frac{z_{i}}{a_{ii}} - \sum_{k=i+1}^{n} x_{k}\cdot \frac{a_{ik}}{a_{ii}}$"></SPAN></TD>
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="111" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img2810.png"
 ALT="$\displaystyle i = n - 1,\ldots,1$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">70</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The forward elimination in the Gaussian algorithm requires
approximately <SPAN CLASS="MATH"><IMG
 WIDTH="36" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img2811.png"
 ALT="$ n^3/3$"></SPAN>, the backward substitution <SPAN CLASS="MATH"><IMG
 WIDTH="36" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img2812.png"
 ALT="$ n^2/2$"></SPAN> operations.

<P>

<H2><A NAME="SECTION001623000000000000000">
Gauss-Jordan method</A>
</H2>

<P>
The Gauss-Jordan method is a modification of the Gaussian elimination.
In each k-th elimination step the elements of the k-th column get zero
except the diagonal element which gets 1.  When the right hand side
vector z is included in each step it contains the solution vector x
afterwards.

<P>
<P>
The following recursive formulas must be applied to get the new matrix
elements for the k-th elimination step.  The k-th row must be computed
first.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><TABLE CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="26" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2813.png"
 ALT="$\displaystyle a_{kj}$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="74" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img2814.png"
 ALT="$\displaystyle = a_{kj} / a_{kk}$"></SPAN></TD>
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="74" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img2815.png"
 ALT="$\displaystyle j = 1\ldots n$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">71</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="19" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2816.png"
 ALT="$\displaystyle z_{k}$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="67" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img2817.png"
 ALT="$\displaystyle = z_{k} / a_{kk}$"></SPAN></TD>
<TD>&nbsp;</TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">72</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
Then the other rows can be calculated with the following formulas.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><TABLE CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="23" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2792.png"
 ALT="$\displaystyle a_{ij}$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="112" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2818.png"
 ALT="$\displaystyle = a_{ij} - a_{ik}\cdot a_{kj}$"></SPAN></TD>
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="278" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2819.png"
 ALT="$\displaystyle j = 1,\ldots,n \textrm{ and } i = 1,\ldots,n \textrm{ with } i \ne k$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">73</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2797.png"
 ALT="$\displaystyle z_{i}$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="98" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2820.png"
 ALT="$\displaystyle = z_{i} - a_{ik}\cdot z_{k}$"></SPAN></TD>
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="160" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2821.png"
 ALT="$\displaystyle i = 1,\ldots,n \textrm{ with } i \ne k$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">74</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
Column pivoting may be necessary in order to avoid division by zero.
The solution vector x is not harmed by row substitutions.  When the
Gauss-Jordan algorithm has been finished the original matrix has been
transformed into the identity matrix.  If each operation during this
process is applied to an identity matrix the resulting matrix is the
inverse matrix of the original matrix.  This means that the
Gauss-Jordan method can be used to compute the inverse of a matrix.

<P>
<P>
Though this elimination method is easy to implement the number of
required operations is larger than within the Gaussian elimination.
The Gauss-Jordan method requires approximately <!-- MATH
 $N^3/2 + N^2/2$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="98" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img2822.png"
 ALT="$ N^3/2 + N^2/2$"></SPAN>
operations.

<P>

<H2><A NAME="SECTION001624000000000000000">
LU decomposition</A>
</H2>

<P>
LU decomposition (decomposition into a lower and upper triangular
matrix) is recommended when dealing with equation systems where the
matrix A does not alter but the right hand side (the vector z) does.
Both the Gaussian elimination and the Gauss-Jordan method involve both
the right hand side and the matrix in their algorithm.  Consecutive
solutions of an equation system with an altering right hand side can
be computed faster with LU decomposition.

<P>
<P>
The LU decomposition splits a matrix A into a product of a lower
triangular matrix L with an upper triangular matrix U.

<P>
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
A = L U \;\text{ with }\;
L =
\begin{bmatrix}
l_{11} & 0 & \ldots & 0\\
l_{21} & l_{22} & \ddots & \vdots\\
\vdots &  & \ddots & 0\\
l_{n1} & \ldots & \ldots & l_{nn}
\end{bmatrix}
\;\text{ and }\;
U =
\begin{bmatrix}
u_{11} & u_{12} & \ldots & u_{1n}\\
0 & u_{22} &  & \vdots\\
\vdots & \ddots & \ddots & \vdots\\
0 & \ldots & 0 & u_{nn}
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="65" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2823.png"
 ALT="$\displaystyle A = L U \;$"> with&nbsp;<IMG
 WIDTH="192" HEIGHT="115" ALIGN="MIDDLE" BORDER="0"
 SRC="img401.png"
 ALT="$\displaystyle \; L = \begin{bmatrix}l_{11} &amp; 0 &amp; \ldots &amp; 0\\ l_{21} &amp; l_{22} &amp;...
...ts\\ \vdots &amp; &amp; \ddots &amp; 0\\ l_{n1} &amp; \ldots &amp; \ldots &amp; l_{nn} \end{bmatrix} \;$"> and&nbsp;<IMG
 WIDTH="200" HEIGHT="115" ALIGN="MIDDLE" BORDER="0"
 SRC="img405.png"
 ALT="$\displaystyle \; U = \begin{bmatrix}u_{11} &amp; u_{12} &amp; \ldots &amp; u_{1n}\\ 0 &amp; u_{...
...ots\\ \vdots &amp; \ddots &amp; \ddots &amp; \vdots\\ 0 &amp; \ldots &amp; 0 &amp; u_{nn} \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">75</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The algorithm for solving the linear equation system <SPAN CLASS="MATH"><IMG
 WIDTH="54" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2824.png"
 ALT="$ Ax = z$"></SPAN> involves
three steps:

<UL>
<LI>LU decomposition of the coefficient matrix A
<BR><!-- MATH
 $\rightarrow Ax = LUx = z$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="128" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2825.png"
 ALT="$ \rightarrow Ax = LUx = z$"></SPAN>
</LI>
<LI>introduction of an (unknown) arbitrary vector y and solving the equation system <SPAN CLASS="MATH"><IMG
 WIDTH="52" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2826.png"
 ALT="$ Ly = z$"></SPAN> by forward substitution
<BR><!-- MATH
 $\rightarrow y = Ux = L^{-1}z$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="132" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img2827.png"
 ALT="$ \rightarrow y = Ux = L^{-1}z$"></SPAN>
</LI>
<LI>solving the equation system <SPAN CLASS="MATH"><IMG
 WIDTH="55" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2828.png"
 ALT="$ Ux = y$"></SPAN> by backward substitution
<BR><!-- MATH
 $\rightarrow x = U^{-1}y$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="92" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img2829.png"
 ALT="$ \rightarrow x = U^{-1}y$"></SPAN>
</LI>
</UL>

<P>
The decomposition of the matrix A into a lower and upper triangular
matrix is not unique.  The most important decompositions, based on
Gaussian elimination, are the Doolittle, the Crout and the Cholesky
decomposition.

<P>
<P>
If pivoting is necessary during these algorithms they do not decompose
the matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img380.png"
 ALT="$ A$"></SPAN> but the product with an arbitrary matrix <SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2830.png"
 ALT="$ PA$"></SPAN> (a
permutation of the matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img380.png"
 ALT="$ A$"></SPAN>).  When exchanging rows and columns the
order of the unknowns as represented by the vector <SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img34.png"
 ALT="$ z$"></SPAN> changes as well
and must be saved during this process for the forward substitution in
the algorithms second step.

<P>

<H3><A NAME="SECTION001624100000000000000">
Step 1: LU decomposition</A>
</H3>

<P>
Using the decomposition according to Crout the coefficients of the L
and U matrices can be stored in place the original matrix A.  The
upper triangular matrix U has the form

<P>
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><A NAME="eq:CroutU"></A><!-- MATH
 \begin{equation}
U =
\begin{bmatrix}
1 & u_{12} & \ldots & u_{1n}\\
0 & 1 &  & \vdots\\
\vdots & \ddots & \ddots & u_{n-1,n}\\
0 & \ldots & 0 & 1
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="201" HEIGHT="115" ALIGN="MIDDLE" BORDER="0"
 SRC="img2831.png"
 ALT="$\displaystyle U = \begin{bmatrix}1 &amp; u_{12} &amp; \ldots &amp; u_{1n}\\ 0 &amp; 1 &amp; &amp; \vdots\\ \vdots &amp; \ddots &amp; \ddots &amp; u_{n-1,n}\\ 0 &amp; \ldots &amp; 0 &amp; 1 \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">76</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The diagonal elements <SPAN CLASS="MATH"><IMG
 WIDTH="25" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2832.png"
 ALT="$ u_{jj}$"></SPAN> are ones and thus the determinant <SPAN CLASS="MATH"><IMG
 WIDTH="38" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2833.png"
 ALT="$ det
U$"></SPAN> is one as well.  The elements of the new coefficient matrix <SPAN CLASS="MATH"><IMG
 WIDTH="27" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2834.png"
 ALT="$ LU$"></SPAN>
for the k-th elimination step with <!-- MATH
 $k = 1, \ldots,n$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="86" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2835.png"
 ALT="$ k = 1, \ldots,n$"></SPAN> compute as
follows:
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><TABLE CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="26" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2836.png"
 ALT="$\displaystyle u_{jk}$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="178" HEIGHT="67" ALIGN="MIDDLE" BORDER="0"
 SRC="img2837.png"
 ALT="$\displaystyle = \frac{1}{l_{jj}}\left(a_{jk} - \sum_{r=1}^{j-1} l_{jr} u_{rk}\right)$"></SPAN></TD>
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="11" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img2838.png"
 ALT="$\displaystyle j$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="100" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2839.png"
 ALT="$\displaystyle = 1,\ldots,k-1$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">77</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="22" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2840.png"
 ALT="$\displaystyle l_{jk}$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="129" HEIGHT="68" ALIGN="MIDDLE" BORDER="0"
 SRC="img2841.png"
 ALT="$\displaystyle = a_{jk} - \sum_{r=1}^{k-1} l_{jr} u_{rk}$"></SPAN></TD>
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="11" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img2838.png"
 ALT="$\displaystyle j$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="74" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2842.png"
 ALT="$\displaystyle = k,\ldots,n$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">78</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
Pivoting may be necessary as you are going to divide by the diagonal
element <SPAN CLASS="MATH"><IMG
 WIDTH="21" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2843.png"
 ALT="$ l_{jj}$"></SPAN>.

<P>

<H3><A NAME="SECTION001624200000000000000"></A>
<A NAME="sec:CroutFSubst"></A>
<BR>
Step 2: Forward substitution
</H3>

<P>
The solutions in the arbitrary vector <SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img1156.png"
 ALT="$ y$"></SPAN> are obtained by forward
substituting into the triangulated <SPAN CLASS="MATH"><IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img396.png"
 ALT="$ L$"></SPAN> matrix.  At this stage you need
to remember the order of unknowns in the vector <SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img34.png"
 ALT="$ z$"></SPAN> as changed by
pivoting.  The elements of the solution vector <SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img1156.png"
 ALT="$ y$"></SPAN> are computed by the
following recursive equation.

<P>
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><TABLE CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="17" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img406.png"
 ALT="$\displaystyle y_{i}$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="130" HEIGHT="66" ALIGN="MIDDLE" BORDER="0"
 SRC="img2844.png"
 ALT="$\displaystyle = \frac{z_{i}}{l_{ii}} - \sum_{k=1}^{i-1} y_{k}\cdot \frac{l_{ik}}{l_{ii}}$"></SPAN></TD>
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="83" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img408.png"
 ALT="$\displaystyle i = 1,\ldots,n$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">79</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>

<H3><A NAME="SECTION001624300000000000000"></A>
<A NAME="sec:CroutBSubst"></A>
<BR>
Step 3: Backward substitution
</H3>

<P>
The solutions in the vector <SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img181.png"
 ALT="$ x$"></SPAN> are obtained by backward substituting
into the triangulated <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img398.png"
 ALT="$ U$"></SPAN> matrix.  The elements of the solution vector
<SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img181.png"
 ALT="$ x$"></SPAN> are computed by the following recursive equation.

<P>
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><TABLE CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img409.png"
 ALT="$\displaystyle x_{i}$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="141" HEIGHT="62" ALIGN="MIDDLE" BORDER="0"
 SRC="img2845.png"
 ALT="$\displaystyle = y_{i} - \sum_{k=i+1}^{n} x_{k}\cdot u_{ik}$"></SPAN></TD>
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="83" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img411.png"
 ALT="$\displaystyle i = n,\ldots,1$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">80</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The division by the diagonal elements of the matrix U is not necessary
because of Crouts definition in eq.&nbsp;(<A HREF="#eq:CroutU">15.76</A>) with <!-- MATH
 $u_{ii} =
1$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="52" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2846.png"
 ALT="$ u_{ii} =
1$"></SPAN>.

<P>
<P>
The LU decomposition requires approximately <!-- MATH
 $n^3/3 + n^2 - n/3$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="117" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img2847.png"
 ALT="$ n^3/3 + n^2 - n/3$"></SPAN>
operations for solving a linear equation system.  For <SPAN CLASS="MATH"><IMG
 WIDTH="21" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img637.png"
 ALT="$ M$"></SPAN> consecutive
solutions the method requires <!-- MATH
 $n^3/3 + Mn^2 - n/3$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="134" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img2848.png"
 ALT="$ n^3/3 + Mn^2 - n/3$"></SPAN> operations.

<P>

<H2><A NAME="SECTION001625000000000000000">
QR decomposition</A>
</H2>

<P>
Singular matrices actually having a solution are over- or
under-determined.  These types of matrices can be handled by three
different types of decompositions: Householder, Jacobi (Givens
rotation) and singular value decomposition.  Householder decomposition
factors a matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img380.png"
 ALT="$ A$"></SPAN> into the product of an orthonormal matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img616.png"
 ALT="$ Q$"></SPAN> and
an upper triangular matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img360.png"
 ALT="$ R$"></SPAN>, such that:
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
A = Q\cdot R
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="71" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2849.png"
 ALT="$\displaystyle A = Q\cdot R$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">81</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The Householder decomposition is based on the fact that for any two
different vectors, <SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img2850.png"
 ALT="$ v$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="15" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img2851.png"
 ALT="$ w$"></SPAN>, with <!-- MATH
 $\left\lVert v\right\rVert =
\left\lVert w\right\rVert$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="77" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img2852.png"
 ALT="$ \left\lVert v\right\rVert =
\left\lVert w\right\rVert$"></SPAN>, i.e. different vectors of equal length, a
reflection matrix <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2853.png"
 ALT="$ H$"></SPAN> exists such that:
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
H \cdot v = w
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="69" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2854.png"
 ALT="$\displaystyle H \cdot v = w$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">82</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
To obtain the matrix <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2853.png"
 ALT="$ H$"></SPAN>, the vector <SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img2855.png"
 ALT="$ u$"></SPAN> is defined by:
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
u = \dfrac{v - w}{\left\lVert v - w\right\rVert}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="93" HEIGHT="48" ALIGN="MIDDLE" BORDER="0"
 SRC="img2856.png"
 ALT="$\displaystyle u = \dfrac{v - w}{\left\lVert v - w\right\rVert}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">83</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The matrix <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2853.png"
 ALT="$ H$"></SPAN> defined by 
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><A NAME="eq:ReflectionMatrix"></A><!-- MATH
 \begin{equation}
H = I - 2 \cdot u \cdot u^T
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="123" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2857.png"
 ALT="$\displaystyle H = I - 2 \cdot u \cdot u^T$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">84</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
is then the required reflection matrix.

<P>
<P>
The equation system
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
A\cdot x = z
\;\;\;\; \textrm{ is transformed into } \;\;\;\;
Q R\cdot x = z
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="315" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2858.png"
 ALT="$\displaystyle A\cdot x = z \;\;\;\; \textrm{ is transformed into } \;\;\;\; Q R\cdot x = z$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">85</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
With <!-- MATH
 $Q^T\cdot Q = I$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="78" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img2859.png"
 ALT="$ Q^T\cdot Q = I$"></SPAN> this yields
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
Q^T Q R\cdot x = Q^T z
\;\;\;\; \rightarrow \;\;\;\;
R\cdot x = Q^T z
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="265" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2860.png"
 ALT="$\displaystyle Q^T Q R\cdot x = Q^T z \;\;\;\; \rightarrow \;\;\;\; R\cdot x = Q^T z$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">86</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
Since <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img360.png"
 ALT="$ R$"></SPAN> is triangular the equation system is solved by a simple
matrix-vector multiplication on the right hand side and backward
substitution.

<P>

<H3><A NAME="SECTION001625100000000000000">
Step 1: QR decomposition</A>
</H3>

<P>
Starting with <SPAN CLASS="MATH"><IMG
 WIDTH="56" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2861.png"
 ALT="$ A_1 = A$"></SPAN>, let <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2862.png"
 ALT="$ v_1$"></SPAN> = the first column of <SPAN CLASS="MATH"><IMG
 WIDTH="23" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2863.png"
 ALT="$ A_1$"></SPAN>, and
<!-- MATH
 $w_1^T = \left(\pm\lVert v_1\rVert , 0 , \ldots 0\right)$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="153" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img2864.png"
 ALT="$ w_1^T = \left(\pm\lVert v_1\rVert , 0 , \ldots 0\right)$"></SPAN>, i.e. a column
vector whose first component is the norm of <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2862.png"
 ALT="$ v_1$"></SPAN> with the remaining
components equal to 0.  The Householder transformation <!-- MATH
 $H_1 = I - 2
\cdot u_1 \cdot u_1^T$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="136" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img2865.png"
 ALT="$ H_1 = I - 2
\cdot u_1 \cdot u_1^T$"></SPAN> with <!-- MATH
 $u_1 = v_1 - w_1 / \lVert v_1 - w_1
\rVert$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="171" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img2866.png"
 ALT="$ u_1 = v_1 - w_1 / \lVert v_1 - w_1
\rVert$"></SPAN> will turn the first column of <SPAN CLASS="MATH"><IMG
 WIDTH="23" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2863.png"
 ALT="$ A_1$"></SPAN> into <SPAN CLASS="MATH"><IMG
 WIDTH="22" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2867.png"
 ALT="$ w_1$"></SPAN> as with <!-- MATH
 $H_1
\cdot A_1 = A_2$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="93" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2868.png"
 ALT="$ H_1
\cdot A_1 = A_2$"></SPAN>.  At each stage <SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$ k$"></SPAN>, <SPAN CLASS="MATH"><IMG
 WIDTH="19" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2869.png"
 ALT="$ v_k$"></SPAN> = the kth column of <SPAN CLASS="MATH"><IMG
 WIDTH="23" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2870.png"
 ALT="$ A_k$"></SPAN>
on and below the diagonal with all other components equal to 0, and
<SPAN CLASS="MATH"><IMG
 WIDTH="23" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2871.png"
 ALT="$ w_k$"></SPAN>'s kth component equals the norm of <SPAN CLASS="MATH"><IMG
 WIDTH="19" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2869.png"
 ALT="$ v_k$"></SPAN> with all other
components equal to 0.  Letting <!-- MATH
 $H_k \cdot A_k = A_{k+1}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="111" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2872.png"
 ALT="$ H_k \cdot A_k = A_{k+1}$"></SPAN>, the
components of the kth column of <SPAN CLASS="MATH"><IMG
 WIDTH="39" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2873.png"
 ALT="$ A_{k+1}$"></SPAN> below the diagonal are each
0.  These calculations are listed below for each stage for the matrix
A.

<P>
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\begin{split}
v_1 =
\begin{bmatrix}
a_{11}\\
a_{21}\\
\vdots\\
a_{n1}
\end{bmatrix}
\;\;\;
w_1 =
\begin{bmatrix}
\pm\lVert v_1 \rVert\\
0\\
\vdots\\
0
\end{bmatrix}
\;\;\;
u_1 = \dfrac{v_1 - w_1}{\left\lVert v_1 - w_1\right\rVert} =
\begin{bmatrix}
u_{11}\\
u_{21}\\
\vdots\\
u_{n1}
\end{bmatrix}
\\
H_1 = I - 2 \cdot u_1 \cdot u_1^T
\;\;\; \rightarrow \;\;\;
H_1 \cdot A_1 = A_2 =
\begin{bmatrix}
a_{11} & a_{12} & \ldots & a_{1n}\\
0 & a_{22} & \ldots & a_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
0 & a_{n2} & \ldots & a_{nn}
\end{bmatrix}
\end{split}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="446" HEIGHT="187" BORDER="0"
 SRC="img2874.png"
 ALT="\begin{displaymath}\begin{split}v_1 = \begin{bmatrix}a_{11}\\ a_{21}\\ \vdots\\ ...
...\vdots\\ 0 &amp; a_{n2} &amp; \ldots &amp; a_{nn} \end{bmatrix} \end{split}\end{displaymath}"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">87</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
With this first step the upper left diagonal element of the <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img360.png"
 ALT="$ R$"></SPAN>
matrix, <!-- MATH
 $a_{11} = \pm\lVert v_1 \rVert$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="90" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img2875.png"
 ALT="$ a_{11} = \pm\lVert v_1 \rVert$"></SPAN>, has been generated.  The
elements below are zeroed out.  Since <SPAN CLASS="MATH"><IMG
 WIDTH="24" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2876.png"
 ALT="$ H_1$"></SPAN> can be generated from
<SPAN CLASS="MATH"><IMG
 WIDTH="20" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2877.png"
 ALT="$ u_1$"></SPAN> stored in place of the first column of <SPAN CLASS="MATH"><IMG
 WIDTH="23" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2863.png"
 ALT="$ A_1$"></SPAN> the multiplication
<!-- MATH
 $H_1 \cdot A_1$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="53" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2878.png"
 ALT="$ H_1 \cdot A_1$"></SPAN> can be performed without actually generating <SPAN CLASS="MATH"><IMG
 WIDTH="24" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2876.png"
 ALT="$ H_1$"></SPAN>.

<P>
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\begin{split}
v_2 =
\begin{bmatrix}
0\\
a_{22}\\
\vdots\\
a_{n2}
\end{bmatrix}
\;\;\;
w_1 =
\begin{bmatrix}
0\\
\pm\lVert v_2 \rVert\\
\vdots\\
0
\end{bmatrix}
\;\;\;
u_2 = \dfrac{v_2 - w_2}{\left\lVert v_2 - w_2\right\rVert} =
\begin{bmatrix}
0\\
u_{22}\\
\vdots\\
u_{n2}
\end{bmatrix}
\\
H_2 = I - 2 \cdot u_2 \cdot u_2^T
\;\;\; \rightarrow \;\;\;
H_2 \cdot A_2 = A_3 =
\begin{bmatrix}
a_{11} & a_{12} & \ldots & a_{1n}\\
0 & a_{22} & \ldots & a_{2n}\\
\vdots & 0 & \ddots & \vdots\\
0 & 0 &  & a_{nn}
\end{bmatrix}
\end{split}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="445" HEIGHT="187" BORDER="0"
 SRC="img2879.png"
 ALT="\begin{displaymath}\begin{split}v_2 = \begin{bmatrix}0\\ a_{22}\\ \vdots\\ a_{n2...
... &amp; \ddots &amp; \vdots\\ 0 &amp; 0 &amp; &amp; a_{nn} \end{bmatrix} \end{split}\end{displaymath}"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">88</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
These elimination steps generate the <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img360.png"
 ALT="$ R$"></SPAN> matrix because <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img616.png"
 ALT="$ Q$"></SPAN> is
orthonormal, i.e.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\begin{split}
A = Q\cdot R
\;\;\; \rightarrow \;\;\;
Q^T A = Q^T Q\cdot R
\;\;\; \rightarrow \;\;\;
Q^T A = R
\\
\;\;\; \rightarrow \;\;\;
H_n \cdot \ldots \cdot H_2 \cdot H_1 \cdot A = R
\end{split}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="350" HEIGHT="50" BORDER="0"
 SRC="img2880.png"
 ALT="\begin{displaymath}\begin{split}A = Q\cdot R \;\;\; \rightarrow \;\;\; Q^T A = Q...
...\; H_n \cdot \ldots \cdot H_2 \cdot H_1 \cdot A = R \end{split}\end{displaymath}"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">89</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
<P>
After <SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img383.png"
 ALT="$ n$"></SPAN> elimination steps the original matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img380.png"
 ALT="$ A$"></SPAN> contains the upper
triangular matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img360.png"
 ALT="$ R$"></SPAN>, except for the diagonal elements which can be
stored in some vector.  The lower triangular matrix contains the
Householder vectors <!-- MATH
 $u_1 \ldots u_n$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="61" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2881.png"
 ALT="$ u_1 \ldots u_n$"></SPAN>.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
A =
\begin{bmatrix}
u_{11} & r_{12} & \ldots & r_{1n}\\
u_{21} & u_{22} &  & r_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
u_{n1} & u_{n2} & \ldots & u_{nn}
\end{bmatrix}
\;\;\;\;
R_{diag} =
\begin{bmatrix}
r_{11}\\
r_{22}\\
\vdots\\
r_{nn}
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="322" HEIGHT="103" ALIGN="MIDDLE" BORDER="0"
 SRC="img2882.png"
 ALT="$\displaystyle A = \begin{bmatrix}u_{11} &amp; r_{12} &amp; \ldots &amp; r_{1n}\\ u_{21} &amp; u...
...;\;\; R_{diag} = \begin{bmatrix}r_{11}\\ r_{22}\\ \vdots\\ r_{nn} \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">90</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
With <!-- MATH
 $Q^T = H_1 \cdot H_2 \cdot \ldots \cdot H_n$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="163" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img2883.png"
 ALT="$ Q^T = H_1 \cdot H_2 \cdot \ldots \cdot H_n$"></SPAN> this representation
contains both the <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img616.png"
 ALT="$ Q$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img360.png"
 ALT="$ R$"></SPAN> matrix, in a packed form, of course: <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img616.png"
 ALT="$ Q$"></SPAN>
as a composition of Householder vectors and <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img360.png"
 ALT="$ R$"></SPAN> in the upper
triangular part and its diagonal vector <SPAN CLASS="MATH"><IMG
 WIDTH="41" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2884.png"
 ALT="$ R_{diag}$"></SPAN>.

<P>

<H3><A NAME="SECTION001625200000000000000">
Step 2: Forming the new right hand side</A>
</H3>

<P>
In order to form the right hand side <SPAN CLASS="MATH"><IMG
 WIDTH="34" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img2885.png"
 ALT="$ Q^T z$"></SPAN> let remember
eq. (<A HREF="#eq:ReflectionMatrix">15.84</A>) denoting the reflection matrices used
to compute <SPAN CLASS="MATH"><IMG
 WIDTH="26" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img2886.png"
 ALT="$ Q^T$"></SPAN>.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
H_n\cdot \ldots \cdot H_2\cdot H_1 = Q^T
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="163" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2887.png"
 ALT="$\displaystyle H_n\cdot \ldots \cdot H_2\cdot H_1 = Q^T$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">91</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
Thus it is possible to replace the original right hand side vector <SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img34.png"
 ALT="$ z$"></SPAN>
by
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
H_n\cdot \ldots \cdot H_2\cdot H_1\cdot z = Q^T \cdot z
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="199" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2888.png"
 ALT="$\displaystyle H_n\cdot \ldots \cdot H_2\cdot H_1\cdot z = Q^T \cdot z$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">92</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
which yields for each <!-- MATH
 $k = 1\ldots n$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="75" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2889.png"
 ALT="$ k = 1\ldots n$"></SPAN> the following expression:
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><A NAME="eq:QTz"></A><!-- MATH
 \begin{equation}
H_k \cdot z = \left(I - 2\cdot u_k \cdot u_k^T\right)\cdot z = z - 2\cdot u_k \cdot u_k^T\cdot z
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="320" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2890.png"
 ALT="$\displaystyle H_k \cdot z = \left(I - 2\cdot u_k \cdot u_k^T\right)\cdot z = z - 2\cdot u_k \cdot u_k^T\cdot z$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">93</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The latter <!-- MATH
 $u_k^T\cdot z$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="41" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img2891.png"
 ALT="$ u_k^T\cdot z$"></SPAN> is a simple scalar product of two vectors.
Performing eq. (<A HREF="#eq:QTz">15.93</A>) for each Householder vector finally
results in the new right hand side vector <SPAN CLASS="MATH"><IMG
 WIDTH="34" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img2885.png"
 ALT="$ Q^T z$"></SPAN>.

<P>

<H3><A NAME="SECTION001625300000000000000">
Step 3: Backward substitution</A>
</H3>

<P>
The solutions in the vector <SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img181.png"
 ALT="$ x$"></SPAN> are obtained by backward substituting
into the triangulated <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img360.png"
 ALT="$ R$"></SPAN> matrix.  The elements of the solution vector
<SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img181.png"
 ALT="$ x$"></SPAN> are computed by the following recursive equation.

<P>
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><TABLE CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img409.png"
 ALT="$\displaystyle x_{i}$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="151" HEIGHT="62" ALIGN="MIDDLE" BORDER="0"
 SRC="img2892.png"
 ALT="$\displaystyle = \dfrac{z_{i}}{r_{ii}} - \sum_{k=i+1}^{n} x_{k}\cdot \dfrac{r_{ik}}{r_{ii}}$"></SPAN></TD>
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="83" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img411.png"
 ALT="$\displaystyle i = n,\ldots,1$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">94</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>

<H3><A NAME="SECTION001625400000000000000">
Motivation</A>
</H3>

<P>
Though the QR decomposition has an operation count of <!-- MATH
 $2n^3 + 3n^2$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="72" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img2893.png"
 ALT="$ 2n^3 + 3n^2$"></SPAN>
(which is about six times more than the LU decomposition) it has its
advantages.  The QR factorization method is said to be unconditional
stable and more accurate.  Also it can be used to obtain the
minimum-norm (or least square) solution of under-determined equation
systems.

<DIV ALIGN="CENTER"><A NAME="fig:MNAsingular"></A><A NAME="24145"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 15.3:</STRONG>
circuit with singular modified nodal analysis matrix</CAPTION>
<TR><TD>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="451" HEIGHT="202" ALIGN="BOTTOM" BORDER="0"
 SRC="img2894.png"
 ALT="\includegraphics[width=10cm]{MNAsingular}">

</DIV></TD></TR>
</TABLE>
</DIV>

<P>
The circuit in fig. <A HREF="#fig:MNAsingular">15.3</A> has the following MNA
representation:
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
A x =
\begin{bmatrix}
\frac{1}{R_{2}} & 0 & 0\\
0 & \frac{1}{R_{1}} & -\frac{1}{R_{1}}\\
0 & -\frac{1}{R_{1}} & \frac{1}{R_{1}}
\end{bmatrix}
\cdot
\begin{bmatrix}
V_1\\
V_2\\
V_3
\end{bmatrix}
=
\begin{bmatrix}
0.1 & 0 & 0\\
0 & 0.1 & -0.1\\
0 & -0.1 & 0.1
\end{bmatrix}
\cdot
\begin{bmatrix}
V_1\\
V_2\\
V_3
\end{bmatrix}
=
\begin{bmatrix}
I_1\\
-I_1\\
I_2
\end{bmatrix}
=
\begin{bmatrix}
0.1\\
-0.1\\
0.1
\end{bmatrix}
=
z
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="621" HEIGHT="79" ALIGN="MIDDLE" BORDER="0"
 SRC="img2895.png"
 ALT="$\displaystyle A x = \begin{bmatrix}\frac{1}{R_{2}} &amp; 0 &amp; 0\\ 0 &amp; \frac{1}{R_{1}...
...\\ -I_1\\ I_2 \end{bmatrix} = \begin{bmatrix}0.1\\ -0.1\\ 0.1 \end{bmatrix} = z$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">95</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The second and third row of the matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img380.png"
 ALT="$ A$"></SPAN> are linear dependent and
the matrix is singular because its determinant is zero.  Depending on
the right hand side <SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img34.png"
 ALT="$ z$"></SPAN>, the equation system has none or unlimited
solutions.  This is called an under-determined system.  The discussed
QR decomposition easily computes a valid solution without reducing
accuracy.  The LU decomposition would probably fail because of the
singularity.

<P>

<H3><A NAME="SECTION001625500000000000000">
QR decomposition with column pivoting</A>
</H3>

<P>

<H3><A NAME="SECTION001625600000000000000">
Least norm problem</A>
</H3>

<P>
With some more effort it is possible to obtain the minimum-norm
solution of this problem.  The algorithm as described here would
probably yield the following solution:
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
x =
\begin{bmatrix}
V_1\\
V_2\\
V_3
\end{bmatrix}
=
\begin{bmatrix}
1\\
0\\
1
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="122" HEIGHT="75" ALIGN="MIDDLE" BORDER="0"
 SRC="img2896.png"
 ALT="$\displaystyle x = \begin{bmatrix}V_1\\ V_2\\ V_3 \end{bmatrix} = \begin{bmatrix}1\\ 0\\ 1 \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">96</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
This is one out of unlimited solutions.  The following short
description shows how it is possible to obtain the minimum-norm
solution.  When decomposing the transposed problem
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
A^T = Q\cdot R
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="81" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2897.png"
 ALT="$\displaystyle A^T = Q\cdot R$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">97</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
the minimum-norm solution <SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2898.png"
 ALT="$ \hat{x}$"></SPAN> is obtained by forward substitution of
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
R^T\cdot x = z
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="74" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2899.png"
 ALT="$\displaystyle R^T\cdot x = z$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">98</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
and multiplying the result with <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img616.png"
 ALT="$ Q$"></SPAN>.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\hat{x} = Q\cdot x
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="65" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2900.png"
 ALT="$\displaystyle \hat{x} = Q\cdot x$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">99</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
In the example above this algorithm results in a solution vector with
the least vector norm possible:
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\hat{x} =
\begin{bmatrix}
V_1\\
V_2\\
V_3
\end{bmatrix}
=
\begin{bmatrix}
1\\
-0.5\\
0.5
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="147" HEIGHT="75" ALIGN="MIDDLE" BORDER="0"
 SRC="img2901.png"
 ALT="$\displaystyle \hat{x} = \begin{bmatrix}V_1\\ V_2\\ V_3 \end{bmatrix} = \begin{bmatrix}1\\ -0.5\\ 0.5 \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">100</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
This algorithm outline is also sometimes called LQ decomposition
because of <SPAN CLASS="MATH"><IMG
 WIDTH="26" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img2902.png"
 ALT="$ R^T$"></SPAN> being a lower triangular matrix used by the forward
substitution.

<P>

<H2><A NAME="SECTION001626000000000000000">
Singular value decomposition</A>
</H2>

<P>
Very bad conditioned (ratio between largest and smallest eigenvalue)
matrices, i.e. nearly singular, or even singular matrices (over- or
under-determined equation systems) can be handled by the singular
value decomposition (SVD).  This type of decomposition is defined by
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><A NAME="eq:USV"></A><!-- MATH
 \begin{equation}
A = U\cdot \Sigma\cdot V^H
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="105" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2903.png"
 ALT="$\displaystyle A = U\cdot \Sigma\cdot V^H$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">101</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
where the <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img398.png"
 ALT="$ U$"></SPAN> matrix consists of the orthonormalized eigenvectors
associated with the eigenvalues of <!-- MATH
 $A\cdot A^H$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="49" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img2904.png"
 ALT="$ A\cdot A^H$"></SPAN>, <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img322.png"
 ALT="$ V$"></SPAN> consists of the
orthonormalized eigenvectors of <!-- MATH
 $A^H\cdot A$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="49" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img2905.png"
 ALT="$ A^H\cdot A$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2906.png"
 ALT="$ \Sigma$"></SPAN> is a matrix
with the singular values of <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img380.png"
 ALT="$ A$"></SPAN> (non-negative square roots of the
eigenvalues of <!-- MATH
 $A^H\cdot A$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="49" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img2905.png"
 ALT="$ A^H\cdot A$"></SPAN>) on its diagonal and zeros otherwise.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\Sigma =
\begin{bmatrix}
\sigma_1 & 0 & \cdots & 0\\
0 & \sigma_2 & \cdots & 0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \cdots & \sigma_n
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="174" HEIGHT="103" ALIGN="MIDDLE" BORDER="0"
 SRC="img2907.png"
 ALT="$\displaystyle \Sigma = \begin{bmatrix}\sigma_1 &amp; 0 &amp; \cdots &amp; 0\\ 0 &amp; \sigma_2 ...
...0\\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\ 0 &amp; 0 &amp; \cdots &amp; \sigma_n \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">102</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The singular value decomposition can be used to solve linear equation
systems by simple substitutions
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><TABLE CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="34" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2908.png"
 ALT="$\displaystyle A\cdot x$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2909.png"
 ALT="$\displaystyle = z$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">103</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="91" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2910.png"
 ALT="$\displaystyle U\cdot \Sigma\cdot V^H\cdot x$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2909.png"
 ALT="$\displaystyle = z$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">104</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="69" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2911.png"
 ALT="$\displaystyle \Sigma\cdot V^H\cdot x$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="63" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2912.png"
 ALT="$\displaystyle = U^H\cdot z$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">105</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
since
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
U^H\cdot U = V^H\cdot V = V\cdot V^H = I
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="217" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2913.png"
 ALT="$\displaystyle U^H\cdot U = V^H\cdot V = V\cdot V^H = I$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">106</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
To obtain the decomposition stated in eq.&nbsp;(<A HREF="#eq:USV">15.101</A>) Householder
vectors are computed and their transformations are applied from the
left-hand side and right-hand side to obtain an upper bidiagonal
matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img381.png"
 ALT="$ B$"></SPAN> which has the same singular values as the original <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img380.png"
 ALT="$ A$"></SPAN>
matrix because all of the transformations introduced are orthogonal.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
U_B^{H\,(n)}\cdot\ldots\cdot U_B^{H\,(1)}\cdot A\cdot
V_B^{(1)}\cdot\ldots\cdot V_B^{(n-2)}
= U_B^H\cdot A\cdot V_B = B^{(0)}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="436" HEIGHT="43" ALIGN="MIDDLE" BORDER="0"
 SRC="img2914.png"
 ALT="$\displaystyle U_B^{H\,(n)}\cdot\ldots\cdot U_B^{H\,(1)}\cdot A\cdot V_B^{(1)}\cdot\ldots\cdot V_B^{(n-2)} = U_B^H\cdot A\cdot V_B = B^{(0)}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">107</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
Specifically, <!-- MATH
 $U_B^{H\,(i)}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="45" HEIGHT="43" ALIGN="MIDDLE" BORDER="0"
 SRC="img2915.png"
 ALT="$ U_B^{H\,(i)}$"></SPAN> annihilates the subdiagonal elements in
column <SPAN CLASS="MATH"><IMG
 WIDTH="9" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img53.png"
 ALT="$ i$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="33" HEIGHT="43" ALIGN="MIDDLE" BORDER="0"
 SRC="img2916.png"
 ALT="$ V_B^{(j)}$"></SPAN> zeros out the appropriate elements in row
<SPAN CLASS="MATH"><IMG
 WIDTH="11" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img54.png"
 ALT="$ j$"></SPAN>.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
B^{(0)} =
\begin{bmatrix}
\beta_1 & \delta_2 & 0 & \cdots & 0\\
0 & \beta_2 & \delta_3 & 0 & 0\\
\vdots & 0 & \ddots & \ddots & 0\\
0 & 0 & 0 & \beta_{n-1} & \delta_n\\
0 & 0 & 0 & 0 & \beta_n\\
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="242" HEIGHT="122" ALIGN="MIDDLE" BORDER="0"
 SRC="img2917.png"
 ALT="$\displaystyle B^{(0)} = \begin{bmatrix}\beta_1 &amp; \delta_2 &amp; 0 &amp; \cdots &amp; 0\\ 0 ...
...\\ 0 &amp; 0 &amp; 0 &amp; \beta_{n-1} &amp; \delta_n\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \beta_n\\ \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">108</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
Afterwards an iterative process (which turns out to be a QR iteration)
is used to transform the bidiagonal matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img381.png"
 ALT="$ B$"></SPAN> into a diagonal form by
applying successive Givens transformations (therefore orthogonal as
well) to the bidiagonal matrix.  This iteration is said to have cubic
convergence and yields the final singular values of the matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img380.png"
 ALT="$ A$"></SPAN>.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
B^{(0)} \rightarrow B^{(1)}\rightarrow \ldots \rightarrow \Sigma
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="168" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2918.png"
 ALT="$\displaystyle B^{(0)} \rightarrow B^{(1)}\rightarrow \ldots \rightarrow \Sigma$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">109</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
B^{(k+1)} = \left(\tilde{U}^{(k)}\right)^H\cdot B^{(k)}\cdot \tilde{V}^{(k)}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="216" HEIGHT="52" ALIGN="MIDDLE" BORDER="0"
 SRC="img2919.png"
 ALT="$\displaystyle B^{(k+1)} = \left(\tilde{U}^{(k)}\right)^H\cdot B^{(k)}\cdot \tilde{V}^{(k)}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">110</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
Each of the transformations applied to the bidiagonal matrix is also
applied to the matrices <SPAN CLASS="MATH"><IMG
 WIDTH="25" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2920.png"
 ALT="$ U_B$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img2921.png"
 ALT="$ V_B^H$"></SPAN> which finally yield the <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img398.png"
 ALT="$ U$"></SPAN>
and <SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img2922.png"
 ALT="$ V^H$"></SPAN> matrices after convergence.

<P>
<P>
So far for the algorithm outline.  Without the very details the
following sections briefly describe each part of the singular value
decomposition.

<P>

<H3><A NAME="SECTION001626100000000000000">
Notation</A>
</H3>

<P>
Beforehand some notation marks are going to be defined.

<P>

<UL>
<LI>Conjugate transposed (or adjoint):
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation*}
A \rightarrow \left(A^T\right)^* = \left(A^*\right)^T = A^H
\end{equation*}
 -->
<TABLE CLASS="equation*" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="192" HEIGHT="41" ALIGN="MIDDLE" BORDER="0"
 SRC="img2923.png"
 ALT="$\displaystyle A \rightarrow \left(A^T\right)^* = \left(A^*\right)^T = A^H$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
&nbsp;&nbsp;&nbsp;</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
</LI>
<LI>Euclidean norm:
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation*}
\lVert x \rVert = \sqrt{\sum^n_{i=1} x_i\cdot x^*_1} =
\sqrt{\sum^n_{i=1} \lvert x_i\rvert^2} =
\sqrt{\lvert x_1\rvert^2 + \cdots  + \lvert x_n\rvert^2} = 
\sqrt{x\cdot x^H}
\end{equation*}
 -->
<TABLE CLASS="equation*" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="459" HEIGHT="77" ALIGN="MIDDLE" BORDER="0"
 SRC="img2924.png"
 ALT="$\displaystyle \lVert x \rVert = \sqrt{\sum^n_{i=1} x_i\cdot x^*_1} = \sqrt{\sum...
...} = \sqrt{\lvert x_1\rvert^2 + \cdots + \lvert x_n\rvert^2} = \sqrt{x\cdot x^H}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
&nbsp;&nbsp;&nbsp;</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
</LI>
<LI>Hermitian (or self adjoint):
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation*}
A = A^H
\end{equation*}
 -->
<TABLE CLASS="equation*" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="61" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2925.png"
 ALT="$\displaystyle A = A^H$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
&nbsp;&nbsp;&nbsp;</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
whereas <SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img2926.png"
 ALT="$ A^H$"></SPAN> denotes the conjugate transposed matrix of <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img380.png"
 ALT="$ A$"></SPAN>.  In the
real case the matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img380.png"
 ALT="$ A$"></SPAN> is then said to be ``symmetric''.

<P>
</LI>
<LI>Unitary:
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation*}
A\cdot A^H = A^H\cdot A = I
\end{equation*}
 -->
<TABLE CLASS="equation*" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="146" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2927.png"
 ALT="$\displaystyle A\cdot A^H = A^H\cdot A = I$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
&nbsp;&nbsp;&nbsp;</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
Real matrices <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img380.png"
 ALT="$ A$"></SPAN> with this property are called ``orthogonal''.

<P>
</LI>
</UL>

<P>

<H3><A NAME="SECTION001626200000000000000">
Householder reflector</A>
</H3>

<P>
A Householder matrix is an elementary unitary matrix that is
Hermitian.  Its fundamental use is their ability to transform a vector
<SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img181.png"
 ALT="$ x$"></SPAN> to a multiple of <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img2928.png"
 ALT="$ \vec{e}_1$"></SPAN>, the first column of the identity
matrix.  The elementary Hermitian (i.e. the Householder matrix) is
defined as
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
H = I - 2\cdot u\cdot u^H
\;\;\;\;
\textrm{ where }
\;\;\;\;
u^H\cdot u = 1
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="281" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2929.png"
 ALT="$\displaystyle H = I - 2\cdot u\cdot u^H \;\;\;\; \textrm{ where } \;\;\;\; u^H\cdot u = 1$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">111</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
Beside excellent numerical properties, their application demonstrates
their efficiency.  If <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img380.png"
 ALT="$ A$"></SPAN> is a matrix, then
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><TABLE CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="40" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2930.png"
 ALT="$\displaystyle H\cdot A$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="131" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2931.png"
 ALT="$\displaystyle = A - 2\cdot u\cdot u^H\cdot A$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">112</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD>&nbsp;</TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="160" HEIGHT="44" ALIGN="MIDDLE" BORDER="0"
 SRC="img2932.png"
 ALT="$\displaystyle = A - 2\cdot u\cdot \left(A^H\cdot u\right)^H$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
&nbsp;&nbsp;&nbsp;</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
and hence explicit formation and storage of <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2853.png"
 ALT="$ H$"></SPAN> is not required.  Also
columns (or rows) can be transformed individually exploiting the fact
that <!-- MATH
 $u^H\cdot A$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="46" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img2933.png"
 ALT="$ u^H\cdot A$"></SPAN> yields a scalar product for single columns or rows.

<P>

<H4><A NAME="SECTION001626210000000000000">
Specific case</A>
</H4>

<P>
In order to reduce a 4<SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img268.png"
 ALT="$ \times$"></SPAN>4 matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img380.png"
 ALT="$ A$"></SPAN> to upper triangular form
successive Householder reflectors must be applied.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
A =
\begin{bmatrix}
a_{11} & a_{12} & a_{13} & a_{14}\\
a_{21} & a_{22} & a_{23} & a_{24}\\
a_{31} & a_{32} & a_{33} & a_{34}\\
a_{41} & a_{42} & a_{43} & a_{44}
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="193" HEIGHT="94" ALIGN="MIDDLE" BORDER="0"
 SRC="img2934.png"
 ALT="$\displaystyle A = \begin{bmatrix}a_{11} &amp; a_{12} &amp; a_{13} &amp; a_{14}\\ a_{21} &amp; a...
...1} &amp; a_{32} &amp; a_{33} &amp; a_{34}\\ a_{41} &amp; a_{42} &amp; a_{43} &amp; a_{44} \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">113</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
In the first step the diagonal element <SPAN CLASS="MATH"><IMG
 WIDTH="25" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2935.png"
 ALT="$ a_{11}$"></SPAN> gets replaced and its
below elements get annihilated by the multiplication with an
appropriate Householder vector, also the remaining right-hand columns
get modified.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
u_1 =
\begin{bmatrix}
u_{11}\\
u_{21}\\
u_{31}\\
u_{41}
\end{bmatrix}
\;\;\;\;
H_1 = I - 2\cdot u_1\cdot u_1^H
\;\;\;\;
\rightarrow A_1 = H_1\cdot A =
\begin{bmatrix}
\beta_1 & a_{12}^{(1)} & a_{13}^{(1)} & a_{14}^{(1)}\\
0 & a_{22}^{(1)} & a_{23}^{(1)} & a_{24}^{(1)}\\
0 & a_{32}^{(1)} & a_{33}^{(1)} & a_{34}^{(1)}\\
0 & a_{42}^{(1)} & a_{43}^{(1)} & a_{44}^{(1)}
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="547" HEIGHT="107" ALIGN="MIDDLE" BORDER="0"
 SRC="img2936.png"
 ALT="$\displaystyle u_1 = \begin{bmatrix}u_{11}\\ u_{21}\\ u_{31}\\ u_{41} \end{bmatr...
...} &amp; a_{34}^{(1)}\\ 0 &amp; a_{42}^{(1)} &amp; a_{43}^{(1)} &amp; a_{44}^{(1)} \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">114</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
This process must be repeated
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
u_2 =
\begin{bmatrix}
0\\
u_{22}\\
u_{32}\\
u_{42}
\end{bmatrix}
\;\;\;\;
H_2 = I - 2\cdot u_2\cdot u_2^H
\;\;\;\;
\rightarrow A_2 = H_2\cdot A_1 =
\begin{bmatrix}
\beta_1 & a_{12}^{(2)} & a_{13}^{(2)} & a_{14}^{(2)}\\
0 & \beta_2 & a_{23}^{(2)} & a_{24}^{(2)}\\
0 & 0 & a_{33}^{(2)} & a_{34}^{(2)}\\
0 & 0 & a_{43}^{(2)} & a_{44}^{(2)}
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="554" HEIGHT="107" ALIGN="MIDDLE" BORDER="0"
 SRC="img2937.png"
 ALT="$\displaystyle u_2 = \begin{bmatrix}0\\ u_{22}\\ u_{32}\\ u_{42} \end{bmatrix} \...
...a_{33}^{(2)} &amp; a_{34}^{(2)}\\ 0 &amp; 0 &amp; a_{43}^{(2)} &amp; a_{44}^{(2)} \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">115</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
u_3 =
\begin{bmatrix}
0\\
0\\
u_{33}\\
u_{43}
\end{bmatrix}
\;\;\;\;
H_3 = I - 2\cdot u_3\cdot u_3^H
\;\;\;\;
\rightarrow A_3 = H_3\cdot A_2 =
\begin{bmatrix}
\beta_1 & a_{12}^{(3)} & a_{13}^{(3)} & a_{14}^{(3)}\\
0 & \beta_2 & a_{23}^{(3)} & a_{24}^{(3)}\\
0 & 0 & \beta_3 & a_{34}^{(3)}\\
0 & 0 & 0 & a_{44}^{(3)}
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="554" HEIGHT="107" ALIGN="MIDDLE" BORDER="0"
 SRC="img2938.png"
 ALT="$\displaystyle u_3 = \begin{bmatrix}0\\ 0\\ u_{33}\\ u_{43} \end{bmatrix} \;\;\;...
...{(3)}\\ 0 &amp; 0 &amp; \beta_3 &amp; a_{34}^{(3)}\\ 0 &amp; 0 &amp; 0 &amp; a_{44}^{(3)} \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">116</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
u_4 =
\begin{bmatrix}
0\\
0\\
0\\
u_{44}
\end{bmatrix}
\;\;\;\;
H_4 = I - 2\cdot u_4\cdot u_4^H
\;\;\;\;
\rightarrow A_4 = H_4\cdot A_3 =
\begin{bmatrix}
\beta_1 & a_{12}^{(4)} & a_{13}^{(4)} & a_{14}^{(4)}\\
0 & \beta_2 & a_{23}^{(4)} & a_{24}^{(4)}\\
0 & 0 & \beta_3 & a_{34}^{(4)}\\
0 & 0 & 0 & \beta_4
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="554" HEIGHT="102" ALIGN="MIDDLE" BORDER="0"
 SRC="img2939.png"
 ALT="$\displaystyle u_4 = \begin{bmatrix}0\\ 0\\ 0\\ u_{44} \end{bmatrix} \;\;\;\; H_...
...{24}^{(4)}\\ 0 &amp; 0 &amp; \beta_3 &amp; a_{34}^{(4)}\\ 0 &amp; 0 &amp; 0 &amp; \beta_4 \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">117</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
until the matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img380.png"
 ALT="$ A$"></SPAN> contains an upper triangular matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img360.png"
 ALT="$ R$"></SPAN>.  The
matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img616.png"
 ALT="$ Q$"></SPAN> can be expressed as the the product of the Householder
vectors.  The performed operations deliver
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
H^H_4\cdot H^H_3\cdot H^H_2\cdot H^H_1 \cdot A = Q^H\cdot A = R
\;\;\;\; \rightarrow \;\;\;\;
A = Q\cdot R
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="389" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2940.png"
 ALT="$\displaystyle H^H_4\cdot H^H_3\cdot H^H_2\cdot H^H_1 \cdot A = Q^H\cdot A = R \;\;\;\; \rightarrow \;\;\;\; A = Q\cdot R$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">118</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
since <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img616.png"
 ALT="$ Q$"></SPAN> is unitary.  The matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img616.png"
 ALT="$ Q$"></SPAN> itself can be expressed in terms
of <SPAN CLASS="MATH"><IMG
 WIDTH="22" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2941.png"
 ALT="$ H_i$"></SPAN> using the following transformation.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><TABLE CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2942.png"
 ALT="$\displaystyle Q^H$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="156" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2943.png"
 ALT="$\displaystyle = H^H_4\cdot H^H_3\cdot H^H_2\cdot H^H_1$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
<A NAME="eq:qh_1">(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">119</SPAN>)</A></TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="55" HEIGHT="44" ALIGN="MIDDLE" BORDER="0"
 SRC="img2944.png"
 ALT="$\displaystyle \left(Q^H\right)^H$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="183" HEIGHT="44" ALIGN="MIDDLE" BORDER="0"
 SRC="img2945.png"
 ALT="$\displaystyle = \left(H^H_4\cdot H^H_3\cdot H^H_2\cdot H^H_1\right)^H$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">120</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img626.png"
 ALT="$\displaystyle Q$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="131" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2946.png"
 ALT="$\displaystyle = H_1\cdot H_2\cdot H_3\cdot H_4$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
<A NAME="eq:qh_3">(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">121</SPAN>)</A></TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The eqn.&nbsp;(<A HREF="#eq:qh_1">15.119</A>)-(<A HREF="#eq:qh_3">15.121</A>) are necessary to be mentioned
only in case <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img616.png"
 ALT="$ Q$"></SPAN> is not Hermitian, but still unitary.  Otherwise there
is no difference computing <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img616.png"
 ALT="$ Q$"></SPAN> or <SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img2947.png"
 ALT="$ Q^H$"></SPAN> using the Householder vectors.
No care must be taken in choosing forward or backward accumulation.

<P>

<H4><A NAME="SECTION001626220000000000000">
General case</A>
</H4>

<P>
In the general case it is necessary to find an elementary unitary
matrix
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
H = I - \tau\cdot u\cdot u^H
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="126" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2948.png"
 ALT="$\displaystyle H = I - \tau\cdot u\cdot u^H$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">122</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
that satisfies the following three conditions.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><A NAME="eq:herm_cond"></A><!-- MATH
 \begin{equation}
\left|\tau\right|^2\cdot u^H\cdot u = \tau + \tau^* =
2\cdot Re\left\{\tau \right\}
\;\;\;\; , \;\;\;\;
H^H\cdot x = \gamma\cdot \lVert x \rVert \cdot \vec{e}_1
\;\;\;\; , \;\;\;\;
\lvert \gamma \rvert = 1
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="501" HEIGHT="40" ALIGN="MIDDLE" BORDER="0"
 SRC="img2949.png"
 ALT="$\displaystyle \left\vert\tau\right\vert^2\cdot u^H\cdot u = \tau + \tau^* = 2\c...
...ot \lVert x \rVert \cdot \vec{e}_1 \;\;\;\; , \;\;\;\; \lvert \gamma \rvert = 1$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">123</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
When choosing the elements <!-- MATH
 $u_{ii} = 1$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="52" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2846.png"
 ALT="$ u_{ii} =
1$"></SPAN> it is possible the store the
Householder vectors as well as the upper triangular matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img360.png"
 ALT="$ R$"></SPAN> in the
same storage of the matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img380.png"
 ALT="$ A$"></SPAN>.  The Householder matrices <SPAN CLASS="MATH"><IMG
 WIDTH="22" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2941.png"
 ALT="$ H_i$"></SPAN> can be
completely restored from the Householder vectors.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
A =
\begin{bmatrix}
\beta_1 & a_{12} & a_{13} & a_{14}\\
u_{21} & \beta_2 & a_{23} & a_{24}\\
u_{31} & u_{32} & \beta_3 & a_{34}\\
u_{41} & u_{42} & u_{43} & \beta_4
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="195" HEIGHT="94" ALIGN="MIDDLE" BORDER="0"
 SRC="img2950.png"
 ALT="$\displaystyle A = \begin{bmatrix}\beta_1 &amp; a_{12} &amp; a_{13} &amp; a_{14}\\ u_{21} &amp; ...
... &amp; u_{32} &amp; \beta_3 &amp; a_{34}\\ u_{41} &amp; u_{42} &amp; u_{43} &amp; \beta_4 \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">124</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
There exist several approaches to meet the conditions expressed in
eq. (<A HREF="#eq:herm_cond">15.123</A>).  For fewer computational effort it may be
convenient to choose <SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img682.png"
 ALT="$ \gamma$"></SPAN> to be real valued.  With the notation
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
H^H\cdot x =
H^H\cdot
\begin{bmatrix}
\alpha\\
x_2\\
x_3\\
x_4\\
\end{bmatrix}
=
\begin{bmatrix}
\beta\\
0\\
0\\
0\\
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="199" HEIGHT="94" ALIGN="MIDDLE" BORDER="0"
 SRC="img2951.png"
 ALT="$\displaystyle H^H\cdot x = H^H\cdot \begin{bmatrix}\alpha\\ x_2\\ x_3\\ x_4\\ \end{bmatrix} = \begin{bmatrix}\beta\\ 0\\ 0\\ 0\\ \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">125</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
one possibility is to define the following calculation rules.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><TABLE CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2952.png"
 ALT="$\displaystyle \nu$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="152" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img2953.png"
 ALT="$\displaystyle = sign\left(Re\left\{\alpha\right\}\right)\cdot \lVert x \rVert$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">126</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2954.png"
 ALT="$\displaystyle \tau$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="63" HEIGHT="48" ALIGN="MIDDLE" BORDER="0"
 SRC="img2955.png"
 ALT="$\displaystyle = \dfrac{\alpha + \nu}{\nu}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">127</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2956.png"
 ALT="$\displaystyle \gamma$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="41" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2957.png"
 ALT="$\displaystyle = -1$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">128</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img1297.png"
 ALT="$\displaystyle \beta$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="259" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img2958.png"
 ALT="$\displaystyle = \gamma \cdot \lVert x \rVert = - \lVert x \rVert \;\;\;\; \rightarrow \;\;\;\; \textrm{real valued}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">129</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img1981.png"
 ALT="$\displaystyle u$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="194" HEIGHT="54" ALIGN="MIDDLE" BORDER="0"
 SRC="img2959.png"
 ALT="$\displaystyle = \dfrac{x + \nu\cdot \vec{e}_1}{\alpha + \nu} \;\;\;\; \rightarrow \;\;\;\; u_{ii} = 1$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">130</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
These definitions yield a complex <SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img649.png"
 ALT="$ \tau$"></SPAN>, thus <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2853.png"
 ALT="$ H$"></SPAN> is no more
Hermitian but still unitary.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
H = I - \tau\cdot u\cdot u^H
\;\;\;\; \rightarrow \;\;\;\;
H^H = I - \tau^*\cdot u\cdot u^H
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="327" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2960.png"
 ALT="$\displaystyle H = I - \tau\cdot u\cdot u^H \;\;\;\; \rightarrow \;\;\;\; H^H = I - \tau^*\cdot u\cdot u^H$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">131</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>

<H3><A NAME="SECTION001626300000000000000">
Givens rotation</A>
</H3>

<P>
A Givens rotation is a plane rotation matrix.  Such a plane rotation
matrix is an orthogonal matrix that is different from the identity
matrix only in four elements.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><A NAME="eq:rotation"></A><!-- MATH
 \begin{equation}
M =
\left[
\begin{array}{ccccccccccc}
1 & 0 & \cdots &  &  &  &  &  &  & \cdots & 0\\
0 & \ddots &  &  &  &  &  &  &  &  & \vdots\\
\vdots &  & 1 &  &  &  &  &  &  &  & \\
 &  &  & +c & 0 & \cdots & 0 & +s &  &  & \\
 &  &  & 0 & 1 &  &  & 0 &  &  & \\
 &  &  & \vdots &  & \ddots &  & \vdots &  &  & \\
 &  &  & 0 &  &  & 1 & 0 &  &  & \\
 &  &  & -s & 0 & \cdots & 0 & +c &  &  & \\
 &  &  &  &  &  &  &  & 1 &  & \vdots\\
\vdots &  &  &  &  &  &  &  &  & \ddots & 0\\
0 & \cdots &  &  &  &  &  &  & \cdots & 0 & 1
\end{array}
\right]
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="403" HEIGHT="279" ALIGN="MIDDLE" BORDER="0"
 SRC="img2961.png"
 ALT="$\displaystyle M = \left[ \begin{array}{ccccccccccc} 1 &amp; 0 &amp; \cdots &amp; &amp; &amp; &amp; &amp; &amp; ...
... &amp; &amp; &amp; \ddots &amp; 0\\ 0 &amp; \cdots &amp; &amp; &amp; &amp; &amp; &amp; &amp; \cdots &amp; 0 &amp; 1 \end{array} \right]$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">132</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The elements are usually chosen so that
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><A NAME="eq:givenscond"></A><!-- MATH
 \begin{equation}
R =
\left[\begin{array}{rl}
c & s\\
-s & c\\
\end{array}\right]
\;\;\;\;  \;\;\;\;
c = \cos{\theta},\; s = \sin{\theta}
\;\;\;\; \rightarrow \;\;\;\;
\left|c\right|^2 + \left|s\right|^2 = 1
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="436" HEIGHT="54" ALIGN="MIDDLE" BORDER="0"
 SRC="img2962.png"
 ALT="$\displaystyle R = \left[\begin{array}{rl} c &amp; s\\ -s &amp; c\\ \end{array}\right] \...
... \rightarrow \;\;\;\; \left\vert c\right\vert^2 + \left\vert s\right\vert^2 = 1$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">133</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The most common use of such a plane rotation is to choose <SPAN CLASS="MATH"><IMG
 WIDTH="10" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img728.png"
 ALT="$ c$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="11" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img2130.png"
 ALT="$ s$"></SPAN>
such that for a given <SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img1064.png"
 ALT="$ a$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="10" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img1065.png"
 ALT="$ b$"></SPAN>
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><A NAME="eq:givensrot"></A><!-- MATH
 \begin{equation}
R =
\left[\begin{array}{rl}
c & s\\
-s & c\\
\end{array}\right]
\cdot
\begin{bmatrix}
a\\
b\\
\end{bmatrix}
=
\begin{bmatrix}
d\\
0\\
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="199" HEIGHT="54" ALIGN="MIDDLE" BORDER="0"
 SRC="img2963.png"
 ALT="$\displaystyle R = \left[\begin{array}{rl} c &amp; s\\ -s &amp; c\\ \end{array}\right] \cdot \begin{bmatrix}a\\ b\\ \end{bmatrix} = \begin{bmatrix}d\\ 0\\ \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">134</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
multiplication annihilates the lower vector entry.  In such an
application the matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img360.png"
 ALT="$ R$"></SPAN> is often termed ``Givens rotation'' matrix.
The following equations satisfy eq.&nbsp;(<A HREF="#eq:givensrot">15.134</A>) for a given
<SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img1064.png"
 ALT="$ a$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="10" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img1065.png"
 ALT="$ b$"></SPAN> exploiting the conditions given in
eq.&nbsp;(<A HREF="#eq:givenscond">15.133</A>).
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
c = \dfrac{\pm a}{\sqrt{\left|a\right|^2 + \left|b\right|^2}}
\;\;\;\; \textrm{and} \;\;\;\;
s = \dfrac{\pm b}{\sqrt{\left|a\right|^2 + \left|b\right|^2}}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="294" HEIGHT="63" ALIGN="MIDDLE" BORDER="0"
 SRC="img2964.png"
 ALT="$\displaystyle c = \dfrac{\pm a}{\sqrt{\left\vert a\right\vert^2 + \left\vert b\...
...s = \dfrac{\pm b}{\sqrt{\left\vert a\right\vert^2 + \left\vert b\right\vert^2}}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">135</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
d = \sqrt{\left|a\right|^2 + \left|b\right|^2}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="116" HEIGHT="52" ALIGN="MIDDLE" BORDER="0"
 SRC="img2965.png"
 ALT="$\displaystyle d = \sqrt{\left\vert a\right\vert^2 + \left\vert b\right\vert^2}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">136</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>

<H3><A NAME="SECTION001626400000000000000">
Eigenvalues of a 2-by-2 matrix</A>
</H3>

<P>
The eigenvalues of a 2-by-2 matrix
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
A =
\begin{bmatrix}
a & b\\
c & d
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="86" HEIGHT="54" ALIGN="MIDDLE" BORDER="0"
 SRC="img2966.png"
 ALT="$\displaystyle A = \begin{bmatrix}a &amp; b\\ c &amp; d \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">137</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
can be obtained directly from the quadratic formula.  The
characteristic polynomial is
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\begin{split}
det\left(A -\mu I\right) =
det
\begin{bmatrix}
a - \mu & b\\
c & d - \mu
\end{bmatrix}
&= \left(a -\mu\right) \cdot \left(d -\mu\right) - bc\\
0 &= \mu^2 - \left(a + d\right)\cdot\mu + \left(ad - bc\right)
\end{split}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="446" HEIGHT="70" BORDER="0"
 SRC="img2967.png"
 ALT="\begin{displaymath}\begin{split}det\left(A -\mu I\right) = det \begin{bmatrix}a ...
...- \left(a + d\right)\cdot\mu + \left(ad - bc\right) \end{split}\end{displaymath}"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">138</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The polynomial yields the two eigenvalues.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><A NAME="eq:eigenvalue"></A><!-- MATH
 \begin{equation}
\mu_{1,2} = \dfrac{a + d}{2} \pm \sqrt{\left(\dfrac{a + d}{2}\right)^2 + bc - ad}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="267" HEIGHT="71" ALIGN="MIDDLE" BORDER="0"
 SRC="img2968.png"
 ALT="$\displaystyle \mu_{1,2} = \dfrac{a + d}{2} \pm \sqrt{\left(\dfrac{a + d}{2}\right)^2 + bc - ad}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">139</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
For a symmetric matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img380.png"
 ALT="$ A$"></SPAN> (i.e. <SPAN CLASS="MATH"><IMG
 WIDTH="39" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2969.png"
 ALT="$ b = c$"></SPAN>) eq.(<A HREF="#eq:eigenvalue">15.139</A>) can
be rewritten to:
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><A NAME="eq:eigenvalue_sym"></A><!-- MATH
 \begin{equation}
\mu_{1,2} = e + d  \pm \sqrt{e^2 + b^2}
\;\;\;\; \textrm{ with } \;\;\;\;
e = \dfrac{a - d}{2}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="316" HEIGHT="52" ALIGN="MIDDLE" BORDER="0"
 SRC="img2970.png"
 ALT="$\displaystyle \mu_{1,2} = e + d \pm \sqrt{e^2 + b^2} \;\;\;\; \textrm{ with } \;\;\;\; e = \dfrac{a - d}{2}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">140</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>

<H3><A NAME="SECTION001626500000000000000">
Step 1: Bidiagonalization</A>
</H3>

<P>
In the first step the original matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img380.png"
 ALT="$ A$"></SPAN> is bidiagonalized by the
application of Householder reflections from the left and right hand
side.  The matrices <SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img2971.png"
 ALT="$ U_B^H$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="24" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2972.png"
 ALT="$ V_B$"></SPAN> can each be determined as a
product of Householder matrices.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\underbrace{U_B^{H\,(n)}\cdot\ldots\cdot U_B^{H\,(1)}}_{U_B^H}\cdot A\cdot
\underbrace{V_B^{(1)}\cdot\ldots\cdot V_B^{(n-2)}}_{V_B}
= U_B^H\cdot A\cdot V_B = B^{(0)}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="441" HEIGHT="75" ALIGN="MIDDLE" BORDER="0"
 SRC="img2973.png"
 ALT="$\displaystyle \underbrace{U_B^{H\,(n)}\cdot\ldots\cdot U_B^{H\,(1)}}_{U_B^H}\cd...
...{V_B^{(1)}\cdot\ldots\cdot V_B^{(n-2)}}_{V_B} = U_B^H\cdot A\cdot V_B = B^{(0)}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">141</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
Each of the required Householder vectors are created and applied as
previously defined.  Suppose a <SPAN CLASS="MATH"><IMG
 WIDTH="42" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img177.png"
 ALT="$ n\times n$"></SPAN> matrix, then applying the
first Householder vector from the left hand side eliminates the first
column and yields
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><TABLE CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="68" HEIGHT="43" ALIGN="MIDDLE" BORDER="0"
 SRC="img2974.png"
 ALT="$\displaystyle U_B^{H\,(1)} \cdot A$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="224" HEIGHT="135" ALIGN="MIDDLE" BORDER="0"
 SRC="img2975.png"
 ALT="$\displaystyle = \begin{bmatrix}\boldsymbol{\beta_1} &amp; a_{12}^{(1)} &amp; a_{13}^{(1...
...\ u_{n1} &amp; a_{n2}^{(1)} &amp; a_{n3}^{(1)} &amp; \cdots &amp; a_{nn}^{(1)} \\ \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">142</SPAN>)</TD></TR>
<TR>
<TD COLSPAN=3 ALIGN="LEFT">
<BR>
Next, a Householder vector is applied from the right hand side to
annihilate the first row.
<P>
<BR></TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="108" HEIGHT="43" ALIGN="MIDDLE" BORDER="0"
 SRC="img2976.png"
 ALT="$\displaystyle U_B^{H\,(1)} \cdot A \cdot V_B^{(1)}$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="224" HEIGHT="132" ALIGN="MIDDLE" BORDER="0"
 SRC="img2977.png"
 ALT="$\displaystyle = \begin{bmatrix}\beta_1 &amp; \boldsymbol{\delta_2} &amp; v_{13} &amp; \cdot...
...\ u_{n1} &amp; a_{n2}^{(2)} &amp; a_{n3}^{(2)} &amp; \cdots &amp; a_{nn}^{(2)} \\ \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">143</SPAN>)</TD></TR>
<TR>
<TD COLSPAN=3 ALIGN="LEFT">
<BR>
Again, a Householder vector is applied from the left hand side to
annihilate the second column.
<P>
<BR></TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="161" HEIGHT="43" ALIGN="MIDDLE" BORDER="0"
 SRC="img2978.png"
 ALT="$\displaystyle U_B^{H\,(2)} \cdot U_B^{H\,(1)} \cdot A \cdot V_B^{(1)}$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="223" HEIGHT="132" ALIGN="MIDDLE" BORDER="0"
 SRC="img2979.png"
 ALT="$\displaystyle = \begin{bmatrix}\beta_1 &amp; \delta_2 &amp; v_{13} &amp; \cdots &amp; v_{1n} \\...
...dots \\ u_{n1} &amp; u_{n2} &amp; a_{n3}^{(3)} &amp; \cdots &amp; a_{nn}^{(3)} \\ \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">144</SPAN>)</TD></TR>
<TR>
<TD COLSPAN=3 ALIGN="LEFT">
<BR>
This process is continued until
<P>
<BR></TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="80" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2980.png"
 ALT="$\displaystyle U_B^H \cdot A \cdot V_B$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="234" HEIGHT="133" ALIGN="MIDDLE" BORDER="0"
 SRC="img2981.png"
 ALT="$\displaystyle = \begin{bmatrix}\beta_1 &amp; \delta_2 &amp; v_{13} &amp; \cdots &amp; v_{1n} \\...
... \delta_n \\ u_{n1} &amp; u_{n2} &amp; u_{n3} &amp; &amp; \boldsymbol{\beta_n} \\ \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">145</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
For each of the Householder transformations from the left and right
hand side the appropriate <SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img649.png"
 ALT="$ \tau$"></SPAN> values must be stored in separate
vectors.

<P>

<H3><A NAME="SECTION001626600000000000000">
Step 2: Matrix reconstructions</A>
</H3>

<P>
Using the Householder vectors stored in place of the original <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img380.png"
 ALT="$ A$"></SPAN>
matrix and the appropriate <SPAN CLASS="MATH"><IMG
 WIDTH="12" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img649.png"
 ALT="$ \tau$"></SPAN> value vectors it is now necessary to
unpack the <SPAN CLASS="MATH"><IMG
 WIDTH="25" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2920.png"
 ALT="$ U_B$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img2921.png"
 ALT="$ V_B^H$"></SPAN> matrices.  The diagonal vector <SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img1147.png"
 ALT="$ \beta$"></SPAN>
and the super-diagonal vector <SPAN CLASS="MATH"><IMG
 WIDTH="11" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2118.png"
 ALT="$ \delta$"></SPAN> can be saved in separate
vectors previously.  Thus the <SPAN CLASS="MATH"><IMG
 WIDTH="25" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2920.png"
 ALT="$ U_B$"></SPAN> matrix can be unpacked in place of
the <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img380.png"
 ALT="$ A$"></SPAN> matrix and the <SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img2921.png"
 ALT="$ V_B^H$"></SPAN> matrix is unpacked in a separate
matrix.

<P>
<P>
There are two possible algorithms for computing the Householder
product matrices, i.e. forward accumulation and backward accumulation.
Both start with the identity matrix which is successively multiplied
by the Householder matrices either from the left or right.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><TABLE CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2982.png"
 ALT="$\displaystyle U_B^H$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="184" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2983.png"
 ALT="$\displaystyle = H^H_{Un}\cdot \ldots \cdot H^H_{U2}\cdot H^H_{U1}\cdot I$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">146</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="68" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2984.png"
 ALT="$\displaystyle \rightarrow\;\;\;\; U_B\;$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="184" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2985.png"
 ALT="$\displaystyle = I\cdot H_{Un}\cdot \ldots \cdot H_{U2}\cdot H_{U1}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">147</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
Recall that the leading portion of each Householder matrix is the
identity except the first.  Thus, at the beginning of backward
accumulation, <SPAN CLASS="MATH"><IMG
 WIDTH="25" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2920.png"
 ALT="$ U_B$"></SPAN> is ``mostly the identity'' and it gradually
becomes full as the iteration progresses.  This pattern can be
exploited to reduce the number of required flops.  In contrast,
<SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img2971.png"
 ALT="$ U_B^H$"></SPAN> is full in forward accumulation after the first step.  For
this reason, backward accumulation is cheaper and the strategy of
choice.  When unpacking the <SPAN CLASS="MATH"><IMG
 WIDTH="25" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2920.png"
 ALT="$ U_B$"></SPAN> matrix in place of the original <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img380.png"
 ALT="$ A$"></SPAN>
matrix it is necessary to choose backward accumulation anyway.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><TABLE CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2986.png"
 ALT="$\displaystyle V_B\;$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="185" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2987.png"
 ALT="$\displaystyle = I\cdot H^H_{V1}\cdot H^H_{V2}\cdot \ldots \cdot H^H_{Vn}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">148</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="66" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2988.png"
 ALT="$\displaystyle \rightarrow\;\;\;\; V_B^H$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="185" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2989.png"
 ALT="$\displaystyle = I\cdot H_{Vn}\cdot \ldots \cdot H_{V2}\cdot H_{V1}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">149</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
Unpacking the <SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img2921.png"
 ALT="$ V_B^H$"></SPAN> matrix is done in a similar way also performing
successive Householder matrix multiplications using backward
accumulation.

<P>

<H3><A NAME="SECTION001626700000000000000">
Step 3: Diagonalization - shifted QR iteration</A>
</H3>

<P>
At this stage the matrices <SPAN CLASS="MATH"><IMG
 WIDTH="25" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2920.png"
 ALT="$ U_B$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img2921.png"
 ALT="$ V_B^H$"></SPAN> exist in unfactored form.
Also there are the diagonal vector <SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img1147.png"
 ALT="$ \beta$"></SPAN> and the super-diagonal
vector <SPAN CLASS="MATH"><IMG
 WIDTH="11" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2118.png"
 ALT="$ \delta$"></SPAN>.  Both vectors are real valued.  Thus the following
algorithm can be applied even though solving a complex equation
system.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
B^{(0)} =
\begin{bmatrix}
\beta_1 & \delta_2 & 0 & \cdots & 0\\
0 & \beta_2 & \delta_3 & 0 & 0\\
\vdots & 0 & \ddots & \ddots & 0\\
0 & 0 & 0 & \beta_{n-1} & \delta_n\\
0 & 0 & 0 & 0 & \beta_n\\
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="242" HEIGHT="122" ALIGN="MIDDLE" BORDER="0"
 SRC="img2917.png"
 ALT="$\displaystyle B^{(0)} = \begin{bmatrix}\beta_1 &amp; \delta_2 &amp; 0 &amp; \cdots &amp; 0\\ 0 ...
...\\ 0 &amp; 0 &amp; 0 &amp; \beta_{n-1} &amp; \delta_n\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \beta_n\\ \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">150</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The remaining problem is thus to compute the SVD of the matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img381.png"
 ALT="$ B$"></SPAN>.
This is done applying an implicit-shift QR step to the tridiagonal
matrix <SPAN CLASS="MATH"><IMG
 WIDTH="72" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img2990.png"
 ALT="$ T=B^T B$"></SPAN> which is a symmetric.  The matrix <SPAN CLASS="MATH"><IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img60.png"
 ALT="$ T$"></SPAN> is not
explicitly formed that is why a QR iteration with implicit shifts is
applied.

<P>
<P>
After bidiagonalization we have a bidiagonal matrix <SPAN CLASS="MATH"><IMG
 WIDTH="34" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img2991.png"
 ALT="$ B^{(0)}$"></SPAN>:
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
B^{(0)} = U_B^H \cdot A \cdot V_B
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="131" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2992.png"
 ALT="$\displaystyle B^{(0)} = U_B^H \cdot A \cdot V_B$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">151</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The presented method turns <SPAN CLASS="MATH"><IMG
 WIDTH="34" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img2993.png"
 ALT="$ B^{(k)}$"></SPAN> into a matrix <SPAN CLASS="MATH"><IMG
 WIDTH="50" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img2994.png"
 ALT="$ B^{(k+1)}$"></SPAN> by
applying a set of orthogonal transforms
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><A NAME="eq:svd_step"></A><!-- MATH
 \begin{equation}
B^{(k+1)} = \tilde{U}^H\cdot B^{(k)} \cdot \tilde{V}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="159" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2995.png"
 ALT="$\displaystyle B^{(k+1)} = \tilde{U}^H\cdot B^{(k)} \cdot \tilde{V}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">152</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The orthogonal matrices <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="21" ALIGN="BOTTOM" BORDER="0"
 SRC="img2996.png"
 ALT="$ \tilde{U}$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="21" ALIGN="BOTTOM" BORDER="0"
 SRC="img2997.png"
 ALT="$ \tilde{V}$"></SPAN> are chosen so that
<SPAN CLASS="MATH"><IMG
 WIDTH="50" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img2994.png"
 ALT="$ B^{(k+1)}$"></SPAN> is also a bidiagonal matrix, but with the super-diagonal
elements smaller than those of <SPAN CLASS="MATH"><IMG
 WIDTH="34" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img2993.png"
 ALT="$ B^{(k)}$"></SPAN>.  The eq.(<A HREF="#eq:svd_step">15.152</A>)
is repeated until the non-diagonal elements of <SPAN CLASS="MATH"><IMG
 WIDTH="50" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img2994.png"
 ALT="$ B^{(k+1)}$"></SPAN> become
smaller than <!-- MATH
 $\varepsilon$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="11" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img2998.png"
 ALT="$ \varepsilon$"></SPAN> and can be disregarded.

<P>
<P>
The matrices <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="21" ALIGN="BOTTOM" BORDER="0"
 SRC="img2996.png"
 ALT="$ \tilde{U}$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="21" ALIGN="BOTTOM" BORDER="0"
 SRC="img2997.png"
 ALT="$ \tilde{V}$"></SPAN> are constructed as
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\tilde{U} = \tilde{U}_1 \cdot \tilde{U}_2 \cdot \tilde{U}_3\cdot \dots \cdot \tilde{U}_{n-1}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="190" HEIGHT="39" ALIGN="MIDDLE" BORDER="0"
 SRC="img2999.png"
 ALT="$\displaystyle \tilde{U} = \tilde{U}_1 \cdot \tilde{U}_2 \cdot \tilde{U}_3\cdot \dots \cdot \tilde{U}_{n-1}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">153</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
and similarly <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="21" ALIGN="BOTTOM" BORDER="0"
 SRC="img2997.png"
 ALT="$ \tilde{V}$"></SPAN> where <!-- MATH
 $\tilde{V}_i$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="39" ALIGN="MIDDLE" BORDER="0"
 SRC="img3000.png"
 ALT="$ \tilde{V}_i$"></SPAN> and <!-- MATH
 $\tilde{U}_i$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="20" HEIGHT="39" ALIGN="MIDDLE" BORDER="0"
 SRC="img3001.png"
 ALT="$ \tilde{U}_i$"></SPAN> are
matrices of simple rotations as given in eq.(<A HREF="#eq:rotation">15.132</A>).  Both
<SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="21" ALIGN="BOTTOM" BORDER="0"
 SRC="img2997.png"
 ALT="$ \tilde{V}$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="21" ALIGN="BOTTOM" BORDER="0"
 SRC="img2996.png"
 ALT="$ \tilde{U}$"></SPAN> are products of Givens rotations and thus
perform orthogonal transforms.

<P>

<H4><A NAME="SECTION001626710000000000000">
Single shifted QR step.</A>
</H4>

<P>
The left multiplication of <SPAN CLASS="MATH"><IMG
 WIDTH="34" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img2993.png"
 ALT="$ B^{(k)}$"></SPAN> by <!-- MATH
 $\tilde{U}_i^H$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="39" ALIGN="MIDDLE" BORDER="0"
 SRC="img3002.png"
 ALT="$ \tilde{U}_i^H$"></SPAN> replaces two
rows of <SPAN CLASS="MATH"><IMG
 WIDTH="34" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img2993.png"
 ALT="$ B^{(k)}$"></SPAN> by their linear combinations.  The rest of <SPAN CLASS="MATH"><IMG
 WIDTH="34" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img2993.png"
 ALT="$ B^{(k)}$"></SPAN>
is unaffected.  Right multiplication of <SPAN CLASS="MATH"><IMG
 WIDTH="34" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img2993.png"
 ALT="$ B^{(k)}$"></SPAN> by <!-- MATH
 $\tilde{V}_i$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="39" ALIGN="MIDDLE" BORDER="0"
 SRC="img3000.png"
 ALT="$ \tilde{V}_i$"></SPAN>
similarly changes only two columns of <SPAN CLASS="MATH"><IMG
 WIDTH="34" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img2993.png"
 ALT="$ B^{(k)}$"></SPAN>.

<P>
<P>
A matrix <!-- MATH
 $\tilde{V}_1$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="20" HEIGHT="39" ALIGN="MIDDLE" BORDER="0"
 SRC="img3003.png"
 ALT="$ \tilde{V}_1$"></SPAN> is chosen the way that
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
B^{(k)}_1 = B^{(k)}_0 \cdot \tilde{V}_1
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="112" HEIGHT="43" ALIGN="MIDDLE" BORDER="0"
 SRC="img3004.png"
 ALT="$\displaystyle B^{(k)}_1 = B^{(k)}_0 \cdot \tilde{V}_1$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">154</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
is a QR transform with a shift.  Note that multiplying <SPAN CLASS="MATH"><IMG
 WIDTH="34" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img2993.png"
 ALT="$ B^{(k)}$"></SPAN> by
<!-- MATH
 $\tilde{V}_1$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="20" HEIGHT="39" ALIGN="MIDDLE" BORDER="0"
 SRC="img3003.png"
 ALT="$ \tilde{V}_1$"></SPAN> gives rise to a non-zero element which is below the main
diagonal.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
B^{(k)}_0 \cdot \tilde{V}_1 =
\begin{bmatrix}
\times & \times & 0 & 0 & 0 & 0\\
\framebox{$\otimes$} & \times & \times & 0 & 0 & 0\\
0 & 0 & \times & \times & 0 & 0\\
0 & 0 & 0 & \times & \times & 0\\
0 & 0 & 0 & 0 & \times & \times\\
0 & 0 & 0 & 0  & 0 & \times\\
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="269" HEIGHT="135" ALIGN="MIDDLE" BORDER="0"
 SRC="img3005.png"
 ALT="$\displaystyle B^{(k)}_0 \cdot \tilde{V}_1 = \begin{bmatrix}\times &amp; \times &amp; 0 ...
...\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \times &amp; \times\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \times\\ \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">155</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
A new rotation angle is then chosen so that multiplication by
<!-- MATH
 $\tilde{U}_1^H$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="39" ALIGN="MIDDLE" BORDER="0"
 SRC="img3006.png"
 ALT="$ \tilde{U}_1^H$"></SPAN> gets rid of that element.  But this will create a
non-zero element which is right beside the super-diagonal.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\tilde{U}_1^H \cdot B^{(k)}_1 =
\begin{bmatrix}
\times & \times & \framebox{$\otimes$} & 0 & 0 & 0\\
0 & \times & \times & 0 & 0 & 0\\
0 & 0 & \times & \times & 0 & 0\\
0 & 0 & 0 & \times & \times & 0\\
0 & 0 & 0 & 0 & \times & \times\\
0 & 0 & 0 & 0  & 0 & \times\\
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="278" HEIGHT="135" ALIGN="MIDDLE" BORDER="0"
 SRC="img3007.png"
 ALT="$\displaystyle \tilde{U}_1^H \cdot B^{(k)}_1 = \begin{bmatrix}\times &amp; \times &amp; ...
...\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \times &amp; \times\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \times\\ \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">156</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
Then <!-- MATH
 $\tilde{V}_2$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="20" HEIGHT="39" ALIGN="MIDDLE" BORDER="0"
 SRC="img3008.png"
 ALT="$ \tilde{V}_2$"></SPAN> is made to make it disappear, but this leads to
another non-zero element below the diagonal, etc.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
B^{(k)}_2 \cdot \tilde{V}_2 =
\begin{bmatrix}
\times & \times & 0 & 0 & 0 & 0\\
0 & \times & \times & 0 & 0 & 0\\
0 & \framebox{$\otimes$} & \times & \times & 0 & 0\\
0 & 0 & 0 & \times & \times & 0\\
0 & 0 & 0 & 0 & \times & \times\\
0 & 0 & 0 & 0  & 0 & \times\\
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="269" HEIGHT="135" ALIGN="MIDDLE" BORDER="0"
 SRC="img3009.png"
 ALT="$\displaystyle B^{(k)}_2 \cdot \tilde{V}_2 = \begin{bmatrix}\times &amp; \times &amp; 0 ...
...\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \times &amp; \times\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \times\\ \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">157</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
In the end, the matrix <!-- MATH
 $\tilde{U}^H B \tilde{V}$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="54" HEIGHT="21" ALIGN="BOTTOM" BORDER="0"
 SRC="img3010.png"
 ALT="$ \tilde{U}^H B \tilde{V}$"></SPAN> becomes bidiagonal
again.  However, because of a special choice of <!-- MATH
 $\tilde{V}_1$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="20" HEIGHT="39" ALIGN="MIDDLE" BORDER="0"
 SRC="img3003.png"
 ALT="$ \tilde{V}_1$"></SPAN> (QR
algorithm), its non-diagonal elements are smaller than those of <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img381.png"
 ALT="$ B$"></SPAN>.

<P>
<P>
Please note that each of the transforms must also be applied to the
unfactored <SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img2971.png"
 ALT="$ U_B^H$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="24" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2972.png"
 ALT="$ V_B$"></SPAN> matrices which turns them successively
into <SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img3011.png"
 ALT="$ U^H$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img322.png"
 ALT="$ V$"></SPAN>

<P>

<H4><A NAME="SECTION001626720000000000000">
Computation of the Wilkinson shift.</A>
</H4>

<P>
For a single QR step the computation of the eigenvalue <SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img122.png"
 ALT="$ \mu$"></SPAN> of the
trailing 2-by-2 submatrix of <!-- MATH
 $T_n = B_n^T\cdot B_n$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="96" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img3012.png"
 ALT="$ T_n = B_n^T\cdot B_n$"></SPAN> that is closer to
the <SPAN CLASS="MATH"><IMG
 WIDTH="23" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3013.png"
 ALT="$ t_{22}$"></SPAN> matrix element is required.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><TABLE CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="188" HEIGHT="54" ALIGN="MIDDLE" BORDER="0"
 SRC="img3014.png"
 ALT="$\displaystyle T_n = \begin{bmatrix}t_{11} &amp; t_{12}\\ t_{21} &amp; t_{22}\\ \end{bmatrix} = B_n^T\cdot B_n$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="256" HEIGHT="75" ALIGN="MIDDLE" BORDER="0"
 SRC="img3015.png"
 ALT="$\displaystyle = \begin{bmatrix}\delta_{n-1} &amp; \beta_{n-1} &amp; 0\\ 0 &amp; \delta_{n} ...
...rix}\delta_{n-1} &amp; 0\\ \beta_{n-1} &amp; \delta_{n}\\ 0 &amp; \beta_{n}\\ \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">158</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD>&nbsp;</TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="198" HEIGHT="54" ALIGN="MIDDLE" BORDER="0"
 SRC="img3016.png"
 ALT="$\displaystyle = \begin{bmatrix}\beta_{n-1}^2 + \delta_{n-1}^2 &amp; \delta_{n}\cdot...
...n-1}\\ \delta_{n}\cdot \beta_{n-1} &amp; \beta_{n}^2 + \delta_{n}^2\\ \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">159</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The required eigenvalue is called Wilkinson shift, see
eq.(<A HREF="#eq:eigenvalue_sym">15.140</A>) for details.  The sign for the eigenvalue
is chosen such that it is closer to <SPAN CLASS="MATH"><IMG
 WIDTH="23" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3013.png"
 ALT="$ t_{22}$"></SPAN>.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><TABLE CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3017.png"
 ALT="$\displaystyle \mu$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="218" HEIGHT="51" ALIGN="MIDDLE" BORDER="0"
 SRC="img3018.png"
 ALT="$\displaystyle = t_{22} + d - sign(d)\cdot \sqrt{d^2 + t_{12}^2}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">160</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD>&nbsp;</TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="305" HEIGHT="71" ALIGN="MIDDLE" BORDER="0"
 SRC="img3019.png"
 ALT="$\displaystyle = t_{22} + d - t_{12}\cdot sign\left(\dfrac{d}{t_{12}}\right)\cdot \sqrt{\left(\dfrac{d}{t_{12}}\right)^2 + 1}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">161</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD>&nbsp;</TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="309" HEIGHT="103" ALIGN="MIDDLE" BORDER="0"
 SRC="img3020.png"
 ALT="$\displaystyle = t_{22} - \dfrac{t_{12}^2}{d + t_{12}\cdot sign\left(\dfrac{d}{t_{12}}\right)\cdot \sqrt{\left(\dfrac{d}{t_{12}}\right)^2 + 1}}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">162</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
whereas
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
d = \dfrac{t_{11} - t_{22}}{2}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="95" HEIGHT="49" ALIGN="MIDDLE" BORDER="0"
 SRC="img3021.png"
 ALT="$\displaystyle d = \dfrac{t_{11} - t_{22}}{2}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">163</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The Givens rotation <!-- MATH
 $\tilde{V}_1$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="20" HEIGHT="39" ALIGN="MIDDLE" BORDER="0"
 SRC="img3003.png"
 ALT="$ \tilde{V}_1$"></SPAN> is chosen such that
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\begin{bmatrix}
c_1 & s_1\\
-s_1 & c_1\\
\end{bmatrix}^T
\cdot
\begin{bmatrix}
(\beta_1^2 - \mu) / \beta_1 \\
\delta_2
\end{bmatrix}
=
\begin{bmatrix}
\times\\
0
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="253" HEIGHT="63" ALIGN="MIDDLE" BORDER="0"
 SRC="img3022.png"
 ALT="$\displaystyle \begin{bmatrix}c_1 &amp; s_1\\ -s_1 &amp; c_1\\ \end{bmatrix}^T \cdot \be...
...) / \beta_1 \\ \delta_2 \end{bmatrix} = \begin{bmatrix}\times\\ 0 \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">164</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The special choice of this first rotation in the single QR step
ensures that the super-diagonal matrix entries get smaller.
Typically, after a few of these QR steps, the super-diagonal entry
<SPAN CLASS="MATH"><IMG
 WIDTH="19" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3023.png"
 ALT="$ \delta_n$"></SPAN> becomes negligible.

<P>

<H4><A NAME="SECTION001626730000000000000">
Zeros on the diagonal or super-diagonal.</A>
</H4>

<P>
The QR iteration described above claims to hold if the underlying
bidiagonal matrix is unreduced, i.e. has no zeros neither on the
diagonal nor on the super-diagonal.

<P>
<P>
When there is a zero along the diagonal, then premultiplication by a
sequence of Givens transformations can zero the right-hand
super-diagonal entry as well.  The inverse rotations must be applied
to the <SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img2971.png"
 ALT="$ U_B^H$"></SPAN> matrix.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><TABLE CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="33" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3024.png"
 ALT="$\displaystyle B =$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="179" HEIGHT="132" ALIGN="MIDDLE" BORDER="0"
 SRC="img3025.png"
 ALT="$\displaystyle \begin{bmatrix}\times &amp; \times &amp; 0 &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; \times &amp; \ti...
...\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \times &amp; \times\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \times\\ \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="20" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3026.png"
 ALT="$\displaystyle \rightarrow$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="179" HEIGHT="132" ALIGN="MIDDLE" BORDER="0"
 SRC="img3027.png"
 ALT="$\displaystyle \begin{bmatrix}\times &amp; \times &amp; 0 &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; \times &amp; \ti...
...\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \times &amp; \times\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \times\\ \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
&nbsp;&nbsp;&nbsp;</TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="20" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3026.png"
 ALT="$\displaystyle \rightarrow$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="179" HEIGHT="132" ALIGN="MIDDLE" BORDER="0"
 SRC="img3028.png"
 ALT="$\displaystyle \begin{bmatrix}\times &amp; \times &amp; 0 &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; \times &amp; \ti...
...\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \times &amp; \times\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \times\\ \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="20" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3026.png"
 ALT="$\displaystyle \rightarrow$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="179" HEIGHT="132" ALIGN="MIDDLE" BORDER="0"
 SRC="img3029.png"
 ALT="$\displaystyle \begin{bmatrix}\times &amp; \times &amp; 0 &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; \times &amp; \ti...
...\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \times &amp; \times\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \times\\ \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
&nbsp;&nbsp;&nbsp;</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
Thus the problem can be decoupled into two smaller matrices <SPAN CLASS="MATH"><IMG
 WIDTH="23" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3030.png"
 ALT="$ B_1$"></SPAN> and
<SPAN CLASS="MATH"><IMG
 WIDTH="23" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3031.png"
 ALT="$ B_2$"></SPAN>.  The diagonal matrix <SPAN CLASS="MATH"><IMG
 WIDTH="23" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3032.png"
 ALT="$ B_3$"></SPAN> is successively getting larger for
each super-diagonal entry being neglected after the QR iterations.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\begin{bmatrix}
B_1 & 0 & 0\\
0 & B_2 & 0\\
0 & 0 & B_3\\
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="114" HEIGHT="75" ALIGN="MIDDLE" BORDER="0"
 SRC="img3033.png"
 ALT="$\displaystyle \begin{bmatrix}B_1 &amp; 0 &amp; 0\\ 0 &amp; B_2 &amp; 0\\ 0 &amp; 0 &amp; B_3\\ \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">165</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
Matrix <SPAN CLASS="MATH"><IMG
 WIDTH="23" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3031.png"
 ALT="$ B_2$"></SPAN> has non-zero super-diagonal entries.  If there is any
zero diagonal entry in <SPAN CLASS="MATH"><IMG
 WIDTH="23" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3031.png"
 ALT="$ B_2$"></SPAN>, then the super-diagonal entry can be
annihilated as just described.  Otherwise the QR iteration algorithm
can be applied to <SPAN CLASS="MATH"><IMG
 WIDTH="23" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3031.png"
 ALT="$ B_2$"></SPAN>.

<P>
<P>
When there are only <SPAN CLASS="MATH"><IMG
 WIDTH="23" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3032.png"
 ALT="$ B_3$"></SPAN> matrix entries left (diagonal entries only)
the algorithm is finished, then the <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img381.png"
 ALT="$ B$"></SPAN> matrix has been transformed
into the singular value matrix <SPAN CLASS="MATH"><IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2906.png"
 ALT="$ \Sigma$"></SPAN>.

<P>

<H3><A NAME="SECTION001626800000000000000">
Step 4: Solving the equation system</A>
</H3>

<P>
It is straight-forward to solve a given equation system once having
the singular value decomposition computed.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><TABLE CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="34" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2908.png"
 ALT="$\displaystyle A\cdot x$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2909.png"
 ALT="$\displaystyle = z$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">166</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="71" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img3034.png"
 ALT="$\displaystyle U\Sigma V^H\cdot x$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="28" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img2909.png"
 ALT="$\displaystyle = z$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">167</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="59" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img3035.png"
 ALT="$\displaystyle \Sigma V^H\cdot x$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="63" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img2912.png"
 ALT="$\displaystyle = U^H\cdot z$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">168</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="47" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img3036.png"
 ALT="$\displaystyle V^H\cdot x$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="91" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img3037.png"
 ALT="$\displaystyle = \Sigma^{-1} U^H \cdot z$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">169</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3038.png"
 ALT="$\displaystyle x$"></SPAN></TD>
<TD NOWRAP ALIGN="LEFT"><SPAN CLASS="MATH"><IMG
 WIDTH="104" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img3039.png"
 ALT="$\displaystyle = V\Sigma^{-1} U^H \cdot z$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
<A NAME="eq:svd_solution">(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">170</SPAN>)</A></TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The inverse of the diagonal matrix <SPAN CLASS="MATH"><IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2906.png"
 ALT="$ \Sigma$"></SPAN> yields
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\Sigma^{-1} =
\begin{bmatrix}
1/\sigma_1 & 0 & \cdots & 0\\
0 & 1/\sigma_2 & \cdots & 0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \cdots & 1/\sigma_n
\end{bmatrix}
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="239" HEIGHT="103" ALIGN="MIDDLE" BORDER="0"
 SRC="img3040.png"
 ALT="$\displaystyle \Sigma^{-1} = \begin{bmatrix}1/\sigma_1 &amp; 0 &amp; \cdots &amp; 0\\ 0 &amp; 1/...
...\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\ 0 &amp; 0 &amp; \cdots &amp; 1/\sigma_n \end{bmatrix}$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">171</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
With <SPAN CLASS="MATH"><IMG
 WIDTH="17" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3041.png"
 ALT="$ v_i$"></SPAN> being the i-th row of the matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img322.png"
 ALT="$ V$"></SPAN>, <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img1861.png"
 ALT="$ u_i$"></SPAN> the i-th column
of the matrix <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img398.png"
 ALT="$ U$"></SPAN> and <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3042.png"
 ALT="$ \sigma_i$"></SPAN> the i-th singular value
eq.&nbsp;(<A HREF="#eq:svd_solution">15.170</A>) can be rewritten to
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
x = \sum_{i=1}^{n} \dfrac{u_i^H\cdot z}{\sigma_i}\cdot v_i
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="125" HEIGHT="62" ALIGN="MIDDLE" BORDER="0"
 SRC="img3043.png"
 ALT="$\displaystyle x = \sum_{i=1}^{n} \dfrac{u_i^H\cdot z}{\sigma_i}\cdot v_i$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">172</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
It must be mentioned that very small singular values <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3042.png"
 ALT="$ \sigma_i$"></SPAN>
corrupt the complete result.  Such values indicate (nearly) singular
(ill-conditioned) matrices <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img380.png"
 ALT="$ A$"></SPAN>.  In such cases, the solution vector
<SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img181.png"
 ALT="$ x$"></SPAN> obtained by zeroing the small <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3042.png"
 ALT="$ \sigma_i$"></SPAN>'s and then using equation
(<A HREF="#eq:svd_solution">15.170</A>) is better than direct-method solutions (such
as LU decomposition or Gaussian elimination) and the SVD solution
where the small <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3042.png"
 ALT="$ \sigma_i$"></SPAN>'s are left non-zero. It may seem
paradoxical that this can be so, since zeroing a singular value
corresponds to throwing away one linear combination of the set of
equations that is going to be solved.  The resolution of the paradox
is that a combination of equations that is so corrupted by roundoff
error is thrown away precisely as to be at best useless; usually it is
worse than useless since it "pulls" the solution vector way off
towards infinity along some direction that is almost a nullspace
vector.

<P>

<H2><A NAME="SECTION001627000000000000000">
Jacobi method</A>
</H2>

<P>
This method quite simply involves rearranging each equation to make
each variable a function of the other variables.  Then make an initial
guess for each solution and iterate.  For this method it is necessary
to ensure that all the diagonal matrix elements <SPAN CLASS="MATH"><IMG
 WIDTH="22" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3044.png"
 ALT="$ a_{ii}$"></SPAN> are non-zero.
This is given for the nodal analysis and almostly given for the
modified nodal analysis.  If the linear equation system is solvable
this can always be achieved by rows substitutions.

<P>
<P>
The algorithm for performing the iteration step <SPAN CLASS="MATH"><IMG
 WIDTH="40" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3045.png"
 ALT="$ k + 1$"></SPAN> writes as
follows.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
x_{i}^{(k+1)} = \dfrac{1}{a_{ii}}\left(z_i - \sum_{j=1}^{i-1} a_{ij}x_{j}^{(k)} - \sum_{j=i+1}^{n} a_{ij}x_{j}^{(k)}\right)
\;\;\;\; \textrm{ for } i = 1, \ldots, n
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="459" HEIGHT="75" ALIGN="MIDDLE" BORDER="0"
 SRC="img3046.png"
 ALT="$\displaystyle x_{i}^{(k+1)} = \dfrac{1}{a_{ii}}\left(z_i - \sum_{j=1}^{i-1} a_{...
...m_{j=i+1}^{n} a_{ij}x_{j}^{(k)}\right) \;\;\;\; \textrm{ for } i = 1, \ldots, n$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">173</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
This has to repeated until the new solution vectors <SPAN CLASS="MATH"><IMG
 WIDTH="47" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img3047.png"
 ALT="$ x^{(k+1)}$"></SPAN>
deviation from the previous one <SPAN CLASS="MATH"><IMG
 WIDTH="30" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img3048.png"
 ALT="$ x^{(k)}$"></SPAN> is sufficiently small.

<P>
<P>
The initial guess has no effect on whether the iterative method
converges or not, but with a good initial guess (as possibly given in
consecutive Newton-Raphson iterations) it converges faster (if it
converges).  To ensure convergence the condition
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\sum_{j = 1, j \ne i}^{n} \left|a_{ij}\right| \le \left|a_{ii}\right|
\;\;\;\; \textrm{ for } i = 1, \ldots, n
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="258" HEIGHT="62" ALIGN="MIDDLE" BORDER="0"
 SRC="img3049.png"
 ALT="$\displaystyle \sum_{j = 1, j \ne i}^{n} \left\vert a_{ij}\right\vert \le \left\vert a_{ii}\right\vert \;\;\;\; \textrm{ for } i = 1, \ldots, n$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">174</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
and at least one case
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\sum_{i = 1, i \ne j}^{n} \left|a_{ij}\right| \le \left|a_{ii}\right|
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="128" HEIGHT="62" ALIGN="MIDDLE" BORDER="0"
 SRC="img3050.png"
 ALT="$\displaystyle \sum_{i = 1, i \ne j}^{n} \left\vert a_{ij}\right\vert \le \left\vert a_{ii}\right\vert$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">175</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
must apply.  If these conditions are not met, the iterative equations
may still converge.  If these conditions are met the iterative
equations will definitely converge.

<P>
<P>
Another simple approach to a convergence criteria for iterative
algorithms is the Schmidt and v. Mises criteria.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
\sqrt{\sum_{i = 1}^n \sum_{j = 1, j \ne i}^n \left|\dfrac{a_{ij}}{a_{ii}}\right|^2} < 1
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="165" HEIGHT="73" ALIGN="MIDDLE" BORDER="0"
 SRC="img3051.png"
 ALT="$\displaystyle \sqrt{\sum_{i = 1}^n \sum_{j = 1, j \ne i}^n \left\vert\dfrac{a_{ij}}{a_{ii}}\right\vert^2} &lt; 1$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">176</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>

<H2><A NAME="SECTION001628000000000000000">
Gauss-Seidel method</A>
</H2>

<P>
The Gauss-Seidel algorithm is a modification of the Jacobi method.  It
uses the previously computed values in the solution vector of the same
iteration step.  That is why this iterative method is expected to
converge faster than the Jacobi method.

<P>
<P>
The slightly modified algorithm for performing the <SPAN CLASS="MATH"><IMG
 WIDTH="40" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img3045.png"
 ALT="$ k + 1$"></SPAN> iteration
step writes as follows.
<P></P>
<DIV ALIGN="CENTER" CLASS="mathdisplay"><!-- MATH
 \begin{equation}
x_{i}^{(k+1)} = \dfrac{1}{a_{ii}}\left(z_i - \sum_{j=1}^{i-1} a_{ij}x_{j}^{(k+1)} - \sum_{j=i+1}^{n} a_{ij}x_{j}^{(k)}\right)
\;\;\;\; \textrm{ for } i = 1, \ldots, n
\end{equation}
 -->
<TABLE CLASS="equation" CELLPADDING="0" WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE">
<TD NOWRAP ALIGN="CENTER"><SPAN CLASS="MATH"><IMG
 WIDTH="475" HEIGHT="75" ALIGN="MIDDLE" BORDER="0"
 SRC="img3052.png"
 ALT="$\displaystyle x_{i}^{(k+1)} = \dfrac{1}{a_{ii}}\left(z_i - \sum_{j=1}^{i-1} a_{...
...m_{j=i+1}^{n} a_{ij}x_{j}^{(k)}\right) \;\;\;\; \textrm{ for } i = 1, \ldots, n$"></SPAN></TD>
<TD NOWRAP CLASS="eqno" WIDTH="10" ALIGN="RIGHT">
(<SPAN CLASS="arabic">15</SPAN>.<SPAN CLASS="arabic">177</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>

<P>
The remarks about the initial guess <SPAN CLASS="MATH"><IMG
 WIDTH="30" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img3053.png"
 ALT="$ x^{(0)}$"></SPAN> as well as the
convergence criteria noted in the section about the Jacobi method
apply to the Gauss-Seidel algorithm as well.

<P>

<H2><A NAME="SECTION001629000000000000000">
A comparison</A>
</H2>

<P>
There are direct and iterative methods (algorithms) for solving linear
equation systems.  Equation systems with large and sparse matrices
should rather be solved with iterative methods.

<P>
<P>
<TABLE CELLPADDING=3 BORDER="1">
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=62>method</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=43>
<DIV ALIGN="RIGHT">precision</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=51>
<DIV ALIGN="RIGHT">application</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=60>
<DIV ALIGN="RIGHT">programming effort</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=48>
<DIV ALIGN="RIGHT">computing complexity</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=84>
<DIV ALIGN="RIGHT">
notes
</DIV></TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=62>Laplace expansion</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=43>
<DIV ALIGN="RIGHT">numerical errors</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=51>
<DIV ALIGN="RIGHT">general</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=60>
<DIV ALIGN="RIGHT">straight forward</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=48>
<DIV ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2788.png"
 ALT="$ n!$"></SPAN></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=84>
<DIV ALIGN="RIGHT">
very time consuming
</DIV></TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=62>Gaussian elimination</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=43>
<DIV ALIGN="RIGHT">numerical errors</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=51>
<DIV ALIGN="RIGHT">general</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=60>
<DIV ALIGN="RIGHT">intermediate</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=48>
<DIV ALIGN="RIGHT"><!-- MATH
 $n^3/3 + n^2/2$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="88" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img3054.png"
 ALT="$ n^3/3 + n^2/2$"></SPAN></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=84>
<DIV ALIGN="RIGHT">

</DIV></TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=62>Gauss-Jordan</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=43>
<DIV ALIGN="RIGHT">numerical errors</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=51>
<DIV ALIGN="RIGHT">general</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=60>
<DIV ALIGN="RIGHT">intermediate</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=48>
<DIV ALIGN="RIGHT"><!-- MATH
 $n^3/3 + n^2 - n/3$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="117" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img2847.png"
 ALT="$ n^3/3 + n^2 - n/3$"></SPAN></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=84>
<DIV ALIGN="RIGHT">
computes the inverse besides
</DIV></TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=62>LU decomposition</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=43>
<DIV ALIGN="RIGHT">numerical errors</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=51>
<DIV ALIGN="RIGHT">general</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=60>
<DIV ALIGN="RIGHT">intermediate</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=48>
<DIV ALIGN="RIGHT"><!-- MATH
 $n^3/3 + n^2 - n/3$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="117" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img2847.png"
 ALT="$ n^3/3 + n^2 - n/3$"></SPAN></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=84>
<DIV ALIGN="RIGHT">
useful for consecutive solutions</DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV>
<P>
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT"></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV>
<P>
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
</DIV></TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=62>QR decomposition</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=43>
<DIV ALIGN="RIGHT">good</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=51>
<DIV ALIGN="RIGHT">general</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=60>
<DIV ALIGN="RIGHT">high</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=48>
<DIV ALIGN="RIGHT"><!-- MATH
 $2n^3 + 3n^3$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="72" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img3055.png"
 ALT="$ 2n^3 + 3n^3$"></SPAN></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=84>
<DIV ALIGN="RIGHT">

</DIV></TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=62>Singular value decomposition</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=43>
<DIV ALIGN="RIGHT">good</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=51>
<DIV ALIGN="RIGHT">general</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=60>
<DIV ALIGN="RIGHT">very high</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=48>
<DIV ALIGN="RIGHT"><!-- MATH
 $2n^3 + 4n^3$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="72" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img3056.png"
 ALT="$ 2n^3 + 4n^3$"></SPAN></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=84>
<DIV ALIGN="RIGHT">
ill-conditioned matrices can be handled</DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV>
<P>
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT"></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV>
<P>
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
<DIV ALIGN="RIGHT">
</DIV></TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=62>Jacobi</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=43>
<DIV ALIGN="RIGHT">very good</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=51>
<DIV ALIGN="RIGHT">diagonally dominant systems</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=60>
<DIV ALIGN="RIGHT">easy</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=48>
<DIV ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="20" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img3057.png"
 ALT="$ n^2$"></SPAN> in each iteration step</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=84>
<DIV ALIGN="RIGHT">
possibly no convergence
</DIV></TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=62>Gauss-Seidel</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=43>
<DIV ALIGN="RIGHT">very good</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=51>
<DIV ALIGN="RIGHT">diagonally dominant systems</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=60>
<DIV ALIGN="RIGHT">easy</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=48>
<DIV ALIGN="RIGHT"><SPAN CLASS="MATH"><IMG
 WIDTH="20" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img3057.png"
 ALT="$ n^2$"></SPAN> in each iteration step</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=84>
<DIV ALIGN="RIGHT">
possibly no convergence
</DIV></TD>
</TR>
</TABLE>

<P>

<DIV CLASS="navigation"><HR><B> Next:</B> <A NAME="tex2html2206"
  HREF="node100.html">Polynomial approximations</A>
<B>Up:</B> <A NAME="tex2html2202"
  HREF="node97.html">Mathematical background</A>
<B> Previous:</B> <A NAME="tex2html2196"
  HREF="node98.html">N-port matrix conversions</A>
</DIV>
<!--End of Navigation Panel-->
<ADDRESS>
<br>This document was generated by <i>Stefan Jahn</i> on <i>2007-12-30</i> using <a href="http://www.latex2html.org">latex2html</a>.
</ADDRESS>
</BODY>
</HTML>
